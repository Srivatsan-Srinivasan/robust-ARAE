{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3: Neural Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework you will build a full neural machine translation system using an attention-based encoder-decoder network to translate from German to English. The encoder-decoder network with attention forms the backbone of many current text generation systems. See [Neural Machine Translation and Sequence-to-sequence Models: A Tutorial](https://arxiv.org/pdf/1703.01619.pdf) for an excellent tutorial that also contains many modern advances.\n",
    "\n",
    "## Goals\n",
    "\n",
    "\n",
    "1. Build a non-attentional baseline model (pure seq2seq as in [ref](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)). \n",
    "2. Incorporate attention into the baseline model ([ref](https://arxiv.org/abs/1409.0473) but with dot-product attention as in class notes).\n",
    "3. Implement beam search: review/tutorial [here](http://www.phontron.com/slides/nlp-programming-en-13-search.pdf)\n",
    "4. Visualize the attention distribution for a few examples. \n",
    "\n",
    "Consult the papers provided for hyperparameters, and the course notes for formal definitions.\n",
    "\n",
    "This will be the most time-consuming assignment in terms of difficulty/training time, so we recommend that you get started early!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This notebook provides a working definition of the setup of the problem itself. Feel free to construct your models inline, or use an external setup (preferred) to build your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text text processing library and methods for pretrained word embeddings\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to process the raw data using a tokenizer. We are going to be using spacy, which can be installed via:  \n",
    "  `[sudo] pip install spacy`  \n",
    "  \n",
    "Tokenizers for English/German can be installed via:  \n",
    "  `[sudo] python -m spacy download en`  \n",
    "  `[sudo] python -m spacy download de`\n",
    "  \n",
    "This isn't *strictly* necessary, and you can use your own tokenization rules if you prefer (e.g. a simple `split()` in addition to some rules to acccount for punctuation), but we recommend sticking to the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we need to add the beginning-of-sentence token `<s>` and the end-of-sentence token `</s>` to the \n",
    "target so we know when to begin/end translating. We do not need to do this on the source side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "DE = data.Field(tokenize=tokenize_de)\n",
    "EN = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, eos_token = EOS_WORD) # only target needs BOS/EOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the data. This may take a few minutes.\n",
    "\n",
    "**While this dataset of 200K sentence pairs is relatively small compared to others, it will still take some time to train. So we are going to be only working with sentences of length at most 20 for this homework. Please train only on this reduced dataset for this homework.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': <torchtext.data.field.Field object at 0x7f905453a2e8>, 'trg': <torchtext.data.field.Field object at 0x7f905453a320>}\n",
      "119076\n",
      "{'trg': ['David', 'Gallo', ':', 'This', 'is', 'Bill', 'Lange', '.', 'I', \"'m\", 'Dave', 'Gallo', '.'], 'src': ['David', 'Gallo', ':', 'Das', 'ist', 'Bill', 'Lange', '.', 'Ich', 'bin', 'Dave', 'Gallo', '.']}\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 20\n",
    "train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(DE, EN), \n",
    "                                         filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
    "                                         len(vars(x)['trg']) <= MAX_LEN)\n",
    "print(train.fields)\n",
    "print(len(train))\n",
    "print(vars(train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the vocabulary and convert the text corpus into indices. We are going to be replacing tokens that occurred less than 5 times with `<unk>` tokens, and take the rest as our vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 113253), (',', 67237), ('ist', 24189), ('die', 23778), ('das', 17102), ('der', 15727), ('und', 15622), ('Sie', 15085), ('es', 13197), ('ich', 12946)]\n",
      "Size of German vocab 13353\n",
      "[('.', 113433), (',', 59512), ('the', 46029), ('to', 29177), ('a', 27548), ('of', 26794), ('I', 24887), ('is', 21775), (\"'s\", 20630), ('that', 19814)]\n",
      "Size of English vocab 11560\n",
      "2 3\n"
     ]
    }
   ],
   "source": [
    "MIN_FREQ = 5\n",
    "DE.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "EN.build_vocab(train.trg, min_freq=MIN_FREQ)\n",
    "print(DE.vocab.freqs.most_common(10))\n",
    "print(\"Size of German vocab\", len(DE.vocab))\n",
    "print(EN.vocab.freqs.most_common(10))\n",
    "print(\"Size of English vocab\", len(EN.vocab))\n",
    "print(EN.vocab.stoi[\"<s>\"], EN.vocab.stoi[\"</s>\"]) #vocab index for <s>, </s>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split our data into batches as usual. Batching for MT is slightly tricky because source/target will be of different lengths. Fortunately, `torchtext` lets you do this by allowing you to pass in a `sort_key` function. This will minimizing the amount of padding on the source side, but since there is still some padding you will inadvertendly \"attend\" to these padding tokens. \n",
    "\n",
    "One way to get rid of padding is to pass a binary `mask` vector to your attention module so its attention score (before the softmax) is minus infinity for the padding token. Another way (which is how we do it for our projects, e.g. opennmt) is to manually sort data into batches so that each batch has exactly the same source length (this means that some batches will be less than the desired batch size, though).\n",
    "\n",
    "However, for this homework padding won't matter too much, so it's fine to ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=BATCH_SIZE, device=-1,\n",
    "                                                  repeat=False, sort_key=lambda x: len(x.src))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to see that the BOS/EOS token is indeed appended to the target (English) sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 10 \n",
      "   795    323   2388      0   4286     77     99      0     20     26     77\n",
      "  6391     43    876      3      3      3    558     33   1515     60     58\n",
      "    42     13      4      0      6     75   8707     13     62     57      5\n",
      "     5     30     24      3      4     13      5     70     36     55   3578\n",
      "   935     17     21   8351      5    162      0     85   6592    328     25\n",
      "    19    404    213    129   3991   2295     18     45      3   2277   1178\n",
      "     8    443     19     21   8424    261     91      5    163     25   3070\n",
      "   283      3      0    109      8      3      3    939     10      7      3\n",
      "    17   1836      0   2060      7     34     61    853     41   1004     43\n",
      "   341     62      3    130   2820    296    873      0      4     38    217\n",
      "    66     34     70     66      2  11554     64    308     45    249      9\n",
      "  2127    623   6905    638   5471     15    107      0    280      3      3\n",
      "  2137     11      0      3    158    444   1635   4850     42   1547     43\n",
      "     7    165     45    344     74      3      3      3      6      3     44\n",
      "  8810      0      5     19      9    889     37      0    596     48    115\n",
      "    54    122   2035    214     19    174      5      0     45   1020     49\n",
      "   200     17      7     68      0     15    472    315   4694      7    232\n",
      "    16    375   7679  10326      0   3699     35    792   9760   6555     94\n",
      "    17      2      2      2      2     16      2      2      2      2     16\n",
      "     1      1      1      1      1      1      1      1      1      1      1\n",
      "\n",
      "Columns 11 to 21 \n",
      "    12     12     12     77   1068     12     20     40     12    517     12\n",
      "    44     34     10     13    115     75  11186     48     92     24     41\n",
      "     0      7      4     94     54     21     62    594      0   6614    203\n",
      "     3    157     22      3     74    216   5959    111      7      2     11\n",
      "     5    335   1915      4      3    396     34     61    566      3     31\n",
      "   127     27      3     58     75      3  12660      3      3      0    141\n",
      "     6      5      5    191     21   1336   5379     31    255      2      7\n",
      "     0      3      0   1774     48     13      3     42     13    155    312\n",
      "  8845      5   3011      2   4279    162   6918      0   1605   2917     69\n",
      "    54    138     50   2135     38      0      3    320    132    142     63\n",
      "     3      3    128     34      7      3   1235     59     15     36      3\n",
      "    27     31     10      7  11977     43      3      3   1209    702     37\n",
      "    37     13     50     96    453     21      0      5      3    953    726\n",
      "     6     14   2533     33      8    723      3     14      8    101     14\n",
      "     0    845     15     78    144      8     70  10423      6    708    348\n",
      "    14     85     94    145      0     13   5762     25     35      2   1568\n",
      "   604   5396     29    895      0  13309      8   7141     19    155     54\n",
      "  2144    239   8328    534      0    171      0  12757      0    142     63\n",
      "     2      2      2      2      2      2      2      2      2      2      2\n",
      "     1      1      1      1      1      1      1      1      1      1      1\n",
      "\n",
      "Columns 22 to 31 \n",
      "    28    250     17    633     97     23     28     99     40     20\n",
      "    47   1109    329    800     10   8580    238    474     10      0\n",
      "    18    116      7     33     22      0   1131      4   1270     34\n",
      "    34     10   9339     13   5116    362     57      3     34      2\n",
      "     5     14    652     41     60      0   3273     31     37     23\n",
      "     0    421   1677     70      3    237     69     13     19      4\n",
      "  1167   6719     18     37      5   4645      3     51      0   1080\n",
      "     3    132    160     22     19   2022      6   1406      8    166\n",
      "     5    438     10  11049   2889   2077   2951    239      0    242\n",
      "  3111      3    385    920     34      8     36      3      6     25\n",
      "   110     38     19     14      5    916      0     19   4116     56\n",
      "     3      5   4234      7   1952   2190   5208   5175   6851   2681\n",
      "    52    121     25    576      7     29   1475     36      3    648\n",
      "   117     15      0   1316     78    237      3    117    628  12361\n",
      "  1721   2051      0      3      0      5     10   3036     10      3\n",
      "   769      3     14     92      3    886     60     14     37  13168\n",
      "    15      5      7   6155      4      0    118      7     22      4\n",
      "   420     13    794     15      6    107     22    388   9572     66\n",
      "     2    239      2     33   8519    222    829   3205  13163      0\n",
      "     1      2     17      2      2      2      2      2      2      2\n",
      "[torch.LongTensor of size 20x32]\n",
      "\n",
      "Target\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 10 \n",
      "     2      2      2      2      2      2      2      2      2      2      2\n",
      "  1039    374     41      0      0     89     42     34     10     97     24\n",
      "    15     32     78      5     13    108    519      0    199     12     56\n",
      "   490     19   2011      0     12     19      0     13    121    120    425\n",
      "    33    230      5      5      6   1116     95     19      6    507     56\n",
      "     6      6     16   2519   1134     68   1016     25   2910    449   9900\n",
      "   449     22   2469     63    543      7      6      8    130    127      9\n",
      "    18   2025      9     31    815    140      0    219     16     35    827\n",
      "    15      0      8     77     18     38      5    145     23   1620      5\n",
      "   144      5   2134     30      6    104     16   4415      8    269     32\n",
      "     5    440      0    308   2530      0     54      7    106      5     26\n",
      "    22     59      5     99    170    773      0     66      9    604     15\n",
      "   305    243    122    135      7      9     32   1076    346      5     74\n",
      "    44     10    425      5      6      0      6     39      8     17     64\n",
      "   791    961     78     31    105     16    418   1087    346    543     55\n",
      "   296    205   2525     77      9     21     11   1035     13    623     25\n",
      "     7    187    134    330     13      3     51      5     23      4    159\n",
      "  6378     22   3658      4     11      1      4   1087      8      3     67\n",
      "    21      3   1098      3      8      1      3   3121   3072      1     21\n",
      "    22      1      4      1      0      1      1      4      4      1      3\n",
      "     3      1      3      1      4      1      1      3      3      1      1\n",
      "     1      1      1      1      3      1      1      1      1      1      1\n",
      "\n",
      "Columns 11 to 21 \n",
      "     2      2      2      2      2      2      2      2      2      2      2\n",
      "    14     14     14     24   1626     14     10     41     14    505     14\n",
      "    64     33     16      5     55    108    868     17    103     39     61\n",
      "     0      6     12     20    110     31     33   3546    637   3841     10\n",
      "     5    119      8     11     72    101   9447     32      0      0    281\n",
      "  2755     19   1119     37    108    640   3794     81      5      5     13\n",
      "    83     28     13    160     15      5    907    101    130   2588     20\n",
      "     0     55     88      5     43     19      5     11     19     61    110\n",
      "     5    124    232     55     17    542   5877     15     77    107     40\n",
      "    25    144   7524     28      6     68      5     36    328     29      6\n",
      "    51      6      0    120   4278      6   1166    157      7    337    106\n",
      "     0    182     63    159    467     47      5      0    891      7     13\n",
      "     0     11     16     20     18     13   5921      5    412    550    470\n",
      "    17     13     12    161     15     31      5    139      5      4    110\n",
      "    82     19   4447      6   1277    409     92     86     18    112     40\n",
      "  2229    126      7    109     71     18   6007    375     20     15   1919\n",
      "     4     78     26      4     82     19      5    237     23      4     17\n",
      "     3   1360     38      3      0   1557     18    502      8      3      6\n",
      "     1      4   5621      1   7308      4   5016      9      0      1    326\n",
      "     1      3      4      1   3307      3      4   3565      4      1      4\n",
      "     1      1      3      1      4      1      3      4      3      1      3\n",
      "     1      1      1      1      3      1      1      3      1      1      1\n",
      "\n",
      "Columns 22 to 31 \n",
      "     2      2      2      2      2      2      2      2      2      2\n",
      "    34   1826     22     34    167      0     34     42     41     10\n",
      "   194      5   1495     80     15      0   2988    256     16   1379\n",
      "    30     19     12     95     28   2067      7     11    288     69\n",
      "  1018  11406    344    148     58      0     40     13     17      4\n",
      "    29      5     38      9    883    170    312     19     51     48\n",
      "     6     17      6    171     13   1145      7     28      8     11\n",
      "   148     66    611     58   2059   3219    225      7      0     37\n",
      "     9    412      0   3906      8      5      6     28      5     58\n",
      "  6345      5     63    769   2523      0   2048      8     18   1134\n",
      "  2718   1094   1669     17     33   5168     29   1058     16   1312\n",
      "    79      7      9    579     55    170      0      5    742      9\n",
      "     7      6   3312      7     12    588    170      8   7232     50\n",
      "   195    100   8496     37    492   4020     44      0    351    982\n",
      "    66     19     45     28      5   2067     12     29      5     12\n",
      "   796     90      0   1731     13    178      8     66      0    413\n",
      "   673      4     17   4266    711      4    918   2538     16    170\n",
      "     4      3      6      4   6624      3      4     17     51    150\n",
      "     3      1    611      3      4      1      3     46      8     11\n",
      "     1      1      4      1      3      1      1     20   4827      0\n",
      "     1      1     22      1      1      1      1      4      4      4\n",
      "     1      1      3      1      1      1      1      3      3      3\n",
      "[torch.LongTensor of size 22x32]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(\"Source\")\n",
    "print(batch.src)\n",
    "print(\"Target\")\n",
    "print(batch.trg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! Now that we've processed the data, we are ready to begin modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "Now it is your turn to build the models described at the top of the assignment. \n",
    "\n",
    "When a model is trained, use the following test function to produce predictions, and then upload to the kaggle competition: https://www.kaggle.com/c/cs287-hw3-s18/\n",
    "\n",
    "For the final Kaggle test, we will provide the source sentence, and you are to predict the **first three words of the target sentence**. The source sentence can be found under `source_test.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head source_test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to HW1, you are to predict the 100 most probable 3-gram that will begin the target sentence. The submission format will be as follows, where each word in the 3-gram will be separated by \"|\", and each 3-gram will be separated by space. For example, here is what an example submission might look like with 5 most-likely 3-grams (instead of 100)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "id,word\n",
    "1,Newspapers|talk|about When|I|was Researchers|call|the Twentysomethings|like|Alex But|before|long\n",
    "2,That|'s|what Newspapers|talk|about You|have|robbed It|'s|realizing My|parents|wanted\n",
    "3,We|forget|how We|think|about Proust|actually|links Does|any|other This|is|something\n",
    "4,But|what|do And|it|'s They|'re|on My|name|is It|only|happens\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you print out your data, you will need to escape quotes and commas with the following command so that Kaggle does not complain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escape(l):\n",
    "    return l.replace(\"\\\"\", \"<quote>\").replace(\",\", \"<comma>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should perform your hyperparameter search/early stopping/write-up based on perplexity, not the above metric. (In practice, people use a metric called [BLEU](https://www.aclweb.org/anthology/P02-1040.pdf), which is roughly a geometric average of 1-gram, 2-gram, 3-gram, 4-gram precision, with a brevity penalty for producing translations that are too short.)\n",
    "\n",
    "Finally, as always please put up a (short) write-up following the template provided in the repository:  https://github.com/harvard-ml-courses/cs287-s18/blob/master/template/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../HW3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "os.chdir('../HW3')  # so that there is not any import bug in case HW2 is not already the working directory\n",
    "from utils import *\n",
    "from const import *\n",
    "import argparse\n",
    "import torch as t\n",
    "from process_params import check_args, get_params\n",
    "from const import *\n",
    "from data_process import generate_iterators, generate_text\n",
    "from utils import *\n",
    "t.manual_seed(1)\n",
    "\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "from utils import variable\n",
    "from const import *\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import spacy\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import pickle\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMA(t.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of `Neural Machine Translation by Jointly Learning to Align and Translate`\n",
    "    https://arxiv.org/abs/1409.0473\n",
    "\n",
    "    NOTE THAT ITS INPUT SHOULD HAVE THE BATCH SIZE FIRST !!!!!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, source_embeddings=None, target_embeddings=None):\n",
    "        super(LSTMA, self).__init__()\n",
    "        print(\"Initializing LSTMA\")\n",
    "        self.cuda_flag = params.get('cuda', CUDA_DEFAULT)\n",
    "        self.model_str = 'LSTMA'\n",
    "        self.params = params\n",
    "\n",
    "        # Initialize hyperparams.\n",
    "        self.hidden_dim = params.get('hidden_dim', 100)\n",
    "        self.batch_size = params.get('batch_size', 32)\n",
    "        try:\n",
    "            # if you provide pre-trained embeddings for target/source, they should have the same embedding dim\n",
    "            assert source_embeddings.size(1) == target_embeddings.size(1)\n",
    "            self.embedding_dim = source_embeddings.size(1)\n",
    "            self.source_vocab_size = params.get('source_vocab_size')\n",
    "            self.target_vocab_size = params.get('target_vocab_size')\n",
    "        except:\n",
    "            # if you dont provide a pre-trained embedding, you have to provide these\n",
    "            self.embedding_dim = params.get('embedding_dim')\n",
    "            self.source_vocab_size = params.get('source_vocab_size')\n",
    "            self.target_vocab_size = params.get('target_vocab_size')\n",
    "            assert self.embedding_dim is not None and self.source_vocab_size is not None and self.target_vocab_size is not None\n",
    "        self.output_size = self.target_vocab_size\n",
    "        self.num_layers = params.get('num_layers', 1)\n",
    "        self.dropout = params.get('dropout', 0.5)\n",
    "        self.embed_dropout = params.get('embed_dropout')\n",
    "        self.train_embedding = params.get('train_embedding', True)\n",
    "\n",
    "        # Initialize embeddings. Static embeddings for now.\n",
    "        self.source_embeddings = t.nn.Embedding(self.source_vocab_size, self.embedding_dim)\n",
    "        self.target_embeddings = t.nn.Embedding(self.target_vocab_size, self.embedding_dim)\n",
    "        if source_embeddings is not None:\n",
    "            self.source_embeddings.weight = t.nn.Parameter(source_embeddings, requires_grad=self.train_embedding)\n",
    "        if target_embeddings is not None:\n",
    "            self.target_embeddings.weight = t.nn.Parameter(target_embeddings, requires_grad=self.train_embedding)\n",
    "\n",
    "        # Initialize network modules.\n",
    "        # note that the encoder is a BiLSTM. The output is modified by the fact that the hidden dim is doubled, and if you set\n",
    "        # the number of layers to L, there will actually be 2L layers (the forward ones and the backward ones). Consequently the first\n",
    "        # dimension of the hidden outputs of the forward pass (the 2nd output in the tuple) will be a tuple of\n",
    "        # 2 tensors having as first dim twice the hidden dim you set\n",
    "        self.encoder_rnn = t.nn.LSTM(self.embedding_dim, self.hidden_dim // 2, dropout=self.dropout, num_layers=self.num_layers, bidirectional=True, batch_first=True)\n",
    "        self.decoder_rnn = t.nn.LSTM(self.embedding_dim, self.hidden_dim, dropout=self.dropout, num_layers=self.num_layers, batch_first=True)\n",
    "        self.hidden_dec_initializer = t.nn.Linear(self.hidden_dim // 2, self.hidden_dim)\n",
    "        self.hidden2out = t.nn.Linear(self.hidden_dim * 2, self.output_size)\n",
    "        if self.embed_dropout:\n",
    "            self.dropout_1s = t.nn.Dropout(self.dropout)\n",
    "            self.dropout_1t = t.nn.Dropout(self.dropout)\n",
    "        self.dropout_2 = t.nn.Dropout(self.dropout)\n",
    "        self.lsm = nn.LogSoftmax()\n",
    "        \n",
    "        self.beam_size = params.get('beam_size',3)\n",
    "        self.max_beam_depth = params.get('max_beam_depth',20)\n",
    "\n",
    "        if self.cuda_flag:\n",
    "            self = self.cuda()\n",
    "\n",
    "    # @todo: maybe this is wrong in case of deep LSTM DECODER (I am not sure the dimensions are correct)\n",
    "    def init_hidden(self, data, type, batch_size=None):\n",
    "        \"\"\"\n",
    "        Initialize the hidden state, either for the encoder or the decoder\n",
    "\n",
    "        For type=`enc`, it should just be initialized with 0s\n",
    "        For type=`dec`, it should be initialized with tanh(W h1_backward) (see page 13 of the paper, last paragraph)\n",
    "\n",
    "        `data` is either something you initialize the hidden state with, or None\n",
    "        \"\"\"\n",
    "        bs = batch_size if batch_size is not None else self.batch_size\n",
    "        if type == 'dec':\n",
    "            # in that case, `data` is the output of the encoder\n",
    "            # data[:, :1, self.hidden_dim // 2:]\n",
    "            # `:` for the whole batch\n",
    "            # `:1` because you want the hidden state of the first time step (see paper, they use backward(h1))\n",
    "            # but also `self.hidden_dim // 2:`, because you want the backward part only (the last coefficients)\n",
    "            h = F.tanh(self.hidden_dec_initializer(data[:, :1, self.hidden_dim // 2:]))  # @todo: verify that the last hdim/2 weights actually correspond to the backward layer(s)\n",
    "            h = h.transpose(1, 0)\n",
    "            return (\n",
    "                h,\n",
    "                variable(np.zeros((self.num_layers, bs, self.hidden_dim)), cuda=self.cuda_flag)\n",
    "            )\n",
    "        elif type == 'enc':\n",
    "            # in that case data is None\n",
    "            return tuple((\n",
    "                variable(np.zeros((self.num_layers * 2, bs, self.hidden_dim // 2)), cuda=self.cuda_flag),\n",
    "                variable(np.zeros((self.num_layers * 2, bs, self.hidden_dim // 2)), cuda=self.cuda_flag)\n",
    "            ))\n",
    "        else:\n",
    "            raise ValueError('the type should be either `dec` or `enc`')\n",
    "\n",
    "    def forward(self, x_source, x_target):\n",
    "        # EMBEDDING\n",
    "        embedded_x_source = self.source_embeddings(x_source)\n",
    "        embedded_x_target = self.target_embeddings(x_target[:, :-1])  # don't make a prediction for the word following the last one\n",
    "        if self.embed_dropout:\n",
    "            embedded_x_source = self.dropout_1s(embedded_x_source)\n",
    "            embedded_x_target = self.dropout_1t(embedded_x_target)\n",
    "\n",
    "        # RECURRENT\n",
    "        hidden = self.init_hidden(None, 'enc', x_source.size(0))\n",
    "        enc_out, _ = self.encoder_rnn(embedded_x_source, hidden)\n",
    "        hidden = self.init_hidden(enc_out, 'dec', x_source.size(0))\n",
    "        dec_out, _ = self.decoder_rnn(embedded_x_target, hidden)\n",
    "\n",
    "        # ATTENTION\n",
    "        scores = t.bmm(enc_out, dec_out.transpose(1, 2))  # this will be a batch x source_len x target_len\n",
    "        attn_dist = F.softmax(scores, dim=1)  # batch x source_len x target_len\n",
    "        context = t.bmm(attn_dist.permute(0, 2, 1), enc_out)  # batch x target_len x hidden_dim\n",
    "\n",
    "        # OUTPUT\n",
    "        # concatenate the output of the decoder and the context and apply nonlinearity\n",
    "        pred = F.tanh(t.cat([dec_out, context], -1))  # @todo : tanh necessary ?\n",
    "        pred = self.dropout_2(pred)  # batch x target_len x 2 hdim\n",
    "        pred = self.hidden2out(pred)\n",
    "        return pred\n",
    "\n",
    "    def translate(self, x_source):\n",
    "        self.eval()\n",
    "\n",
    "        # EMBEDDING\n",
    "        embedded_x_source = self.source_embeddings(x_source)\n",
    "        if self.embed_dropout:\n",
    "            embedded_x_source = self.dropout_1s(embedded_x_source)\n",
    "\n",
    "        # RECURRENT\n",
    "        hidden = self.init_hidden(None, 'enc')\n",
    "        enc_out, _ = self.encoder_rnn(embedded_x_source, hidden)\n",
    "        hidden = self.init_hidden(enc_out, 'dec')\n",
    "        x_target = (SOS_TOKEN * t.ones(x_source.size(0), 1)).long()  # `2` is the SOS token (<s>)\n",
    "        x_target = variable(x_target, to_float=False, cuda=self.cuda_flag)\n",
    "        count_eos = 0\n",
    "        time = 0\n",
    "        while count_eos < x_source.size(0):\n",
    "            embedded_x_target = self.target_embeddings(x_target)\n",
    "            dec_out, hidden = self.decoder_rnn(embedded_x_target, hidden)\n",
    "            hidden = hidden[0].detach(), hidden[1].detach()\n",
    "            dec_out = dec_out[:, time:time + 1, :].detach()\n",
    "\n",
    "            # ATTENTION\n",
    "            scores = t.bmm(enc_out, dec_out.transpose(1, 2))  # this will be a batch x source_len x target_len\n",
    "            try:\n",
    "                attn_dist = F.softmax(scores, dim=1)  # batch x source_len x target_len\n",
    "            except:\n",
    "                attn_dist = F.softmax(scores.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "            context = t.bmm(attn_dist.permute(0, 2, 1), enc_out)  # batch x target_len x hidden_dim\n",
    "\n",
    "            # OUTPUT\n",
    "            # concatenate the output of the decoder and the context and apply nonlinearity\n",
    "            pred = F.tanh(t.cat([dec_out, context], -1))  # @todo : tanh necessary ?\n",
    "            pred = self.dropout_2(pred)  # batch x target_len x 2 hdim\n",
    "            pred = self.hidden2out(pred).detach()\n",
    "            x_target = t.cat([x_target, pred.max(2)[1]], 1).detach()\n",
    "\n",
    "            # should you stop ?\n",
    "            count_eos += t.sum((pred.max(2)[1] == EOS_TOKEN).long()).data.cpu().numpy()[0]  # `3` is the EOS token\n",
    "            time += 1\n",
    "        return x_target\n",
    "    \n",
    "    def translate_beam(self,x_source,print_beam_row=-1):\n",
    "        self.eval()        \n",
    "\n",
    "        # EMBEDDING\n",
    "        embedded_x_source = self.source_embeddings(x_source)\n",
    "        if self.embed_dropout:\n",
    "            embedded_x_source = self.dropout_1s(embedded_x_source)\n",
    "        \n",
    "        terminate_beam = False\n",
    "        batch_size = x_source.size(0)\n",
    "        \n",
    "        # RECURRENT\n",
    "        hidden = self.init_hidden(None, 'enc')\n",
    "        enc_out, _ = self.encoder_rnn(embedded_x_source, hidden)\n",
    "        hidden = self.init_hidden(enc_out, 'dec')\n",
    "        x_target = SOS_TOKEN * np.ones((x_source.size(0), 1))  # `2` is the SOS token (<s>)\n",
    "        count_eos = 0\n",
    "        time = 0        \n",
    "        \n",
    "        #INIT SOME STUFF.\n",
    "        self.beam = np.array([x_target])\n",
    "        self.beam_scores = np.zeros((batch_size,1))\n",
    "        \n",
    "        while not terminate_beam and time < self.max_beam_depth: \n",
    "            \n",
    "            collective_children   = np.array([])\n",
    "            collective_scores     = np.array([])\n",
    "           \n",
    "            if len(self.beam) == 1:\n",
    "                reshaped_beam = self.beam\n",
    "            else:\n",
    "                reshaped_beam = np.transpose(self.beam,(1,0,2))\n",
    "            \n",
    "            for it, elem in enumerate(reshaped_beam) : \n",
    "                elem = t.from_numpy(elem).long()\n",
    "                x_target = elem.contiguous().view(self.batch_size,-1)\n",
    "                x_target = variable(x_target, to_float=False, cuda=self.cuda_flag).long()\n",
    "                embedded_x_target = self.target_embeddings(x_target)\n",
    "                dec_out, hidden = self.decoder_rnn(embedded_x_target, hidden)\n",
    "                hidden = hidden[0].detach(), hidden[1].detach()\n",
    "                dec_out = dec_out[:, time:time + 1, :].detach()\n",
    "    \n",
    "                # ATTENTION\n",
    "                scores = t.bmm(enc_out, dec_out.transpose(1, 2))  # this will be a batch x source_len x target_len\n",
    "                try:\n",
    "                    attn_dist = F.softmax(scores, dim=1)  # batch x source_len x target_len\n",
    "                except:\n",
    "                    attn_dist = F.softmax(scores.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "                context = t.bmm(attn_dist.permute(0, 2, 1), enc_out)  # batch x target_len x hidden_dim\n",
    "    \n",
    "                # OUTPUT\n",
    "                # concatenate the output of the decoder and the context and apply nonlinearity\n",
    "                pred = F.tanh(t.cat([dec_out, context], -1))  # @todo : tanh necessary ?\n",
    "                pred = self.dropout_2(pred)  # batch x target_len x 2 hdim\n",
    "                pred = self.hidden2out(pred).detach()\n",
    "                \n",
    "                pred = self.lsm(pred.view(batch_size,-1)).detach()\n",
    "\n",
    "                topk = t.topk(pred, self.beam_size,dim=1)\n",
    "                #import pdb; pdb.set_trace()\n",
    "            \n",
    "                #topk dimensions - batch * 1 * beam\n",
    "                top_k_indices, top_k_scores = topk[1],topk[0]\n",
    "                \n",
    "                #temporarily get them in beam*batch dimensions to iterate over each beam element.\n",
    "                top_k_indices = top_k_indices.transpose(0,1)\n",
    "                top_k_scores = top_k_scores.transpose(0,1)              \n",
    "                \n",
    "                for new_word_batch, new_score_batch in zip(top_k_indices, top_k_scores):    \n",
    "                    #import pdb; pdb.set_trace()  \n",
    "                    new_word_batch= new_word_batch.contiguous().view(batch_size,1)\n",
    "                    new_score_batch = new_score_batch.contiguous().view(batch_size,1) \n",
    "                    new_child_batch = t.cat([x_target,new_word_batch],1).detach()                    \n",
    "                   \n",
    "                    batch_parent_score = self.beam_scores[:,it].reshape((self.batch_size,1))\n",
    "                    batch_acc_score =  batch_parent_score + new_score_batch.data.cpu().numpy()        \n",
    "                \n",
    "                    if len(collective_children) > 0:\n",
    "                        collective_children = np.hstack((collective_children, new_child_batch.data.cpu().numpy())) \n",
    "                        #Add the corresponding beam element's score with the new score and stack it.\n",
    "                        collective_scores   = np.hstack((collective_scores, batch_acc_score ))              \n",
    "                    else:\n",
    "                        collective_children, collective_scores = new_child_batch.data.cpu().numpy(),batch_acc_score               \n",
    "            #import pdb; pdb.set_trace()\n",
    "                     \n",
    "            #At the end of a for loop collective children, collective scores \n",
    "            #will look a numpy array of tensors.            \n",
    "            current_beam_length = 1 #Means only start elem is there.\n",
    "            if len(self.beam)!= 1:\n",
    "                current_beam_length = self.beam.shape[1]  \n",
    "            \n",
    "            #import pdb; pdb.set_trace()\n",
    "                  \n",
    "            collective_children = collective_children.reshape((batch_size, current_beam_length*self.beam_size, \n",
    "                                                               int(collective_children.shape[1]/\n",
    "                                                                   current_beam_length/self.beam_size)\n",
    "                                                             ))\n",
    "            \n",
    "            if collective_children.shape[1] == self.beam_size:  #Happens the first time.\n",
    "                self.beam = collective_children  \n",
    "                self.beam_scores = collective_scores\n",
    "                if print_beam_row > -1:\n",
    "                    for l in range(self.beam_size):\n",
    "                        print([EN.vocab.itos[int(x)] for x in self.beam[print_beam_row,int(l)]])\n",
    "                             \n",
    "                \n",
    "            else:\n",
    "                self.beam = deepcopy(np.zeros((batch_size,self.beam_size,collective_children.shape[2])))\n",
    "                for i in range(batch_size):\n",
    "                    #Since argsort gives ascending order\n",
    "                    #import pdb; pdb.set_trace()\n",
    "                    best_scores_indices = np.argsort(-1*collective_scores[i])[:self.beam_size]  \n",
    "                    for key,index in enumerate(best_scores_indices):\n",
    "                        self.beam[i][key][:] = collective_children[i][index]                       \n",
    "                        self.beam_scores[i][key] = collective_scores[i][index]\n",
    "                if print_beam_row > -1:\n",
    "                    for l in range(self.beam_size):\n",
    "                        print([EN.vocab.itos[int(x)] for x in self.beam[print_beam_row,int(l)]])\n",
    "           \n",
    "            \n",
    "            terminate_beam = True\n",
    "            \n",
    "            for x in self.beam:\n",
    "                    for c in x:\n",
    "                        if EOS_TOKEN not in c:\n",
    "                            terminate_beam = False\n",
    "                            break\n",
    "                    if not terminate_beam:\n",
    "                        break   \n",
    "            #import pdb; pdb.set_trace()\n",
    "            assert(self.beam.shape == (batch_size,self.beam_size,time+2))\n",
    "\n",
    "            time += 1                 \n",
    "            \n",
    "        return self.beam \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing LSTMA\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from utils import load_model\n",
    "\n",
    "#from translation_models import LSTMA\n",
    "from const import *\n",
    "with open('LSTMA/1.params.json', 'r') as f:\n",
    "    params = json.load(f)\n",
    "params['beam_size'] = 3\n",
    "lstma = LSTMA(params).cuda()\n",
    "load_model(lstma, 'LSTMA/1.pytorch', cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:222: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '<unk>']\n",
      "['<s>', 'And']\n",
      "['<s>', 'So']\n",
      "['<s>', '<unk>', 'has']\n",
      "['<s>', '<unk>', 'is']\n",
      "['<s>', 'So', ',']\n",
      "['<s>', '<unk>', 'has', 'this']\n",
      "['<s>', 'So', ',', '</s>']\n",
      "['<s>', '<unk>', 'has', 'the']\n",
      "['<s>', '<unk>', 'has', 'this', '<unk>']\n",
      "['<s>', 'So', ',', '</s>', '<pad>']\n",
      "['<s>', '<unk>', 'has', 'the', '<unk>']\n",
      "['<s>', 'So', ',', '</s>', '<pad>', '<pad>']\n",
      "['<s>', '<unk>', 'has', 'this', '<unk>', '.']\n",
      "['<s>', '<unk>', 'has', 'the', '<unk>', '.']\n",
      "['<s>', 'So', ',', '</s>', '<pad>', '<pad>', '<pad>']\n",
      "['<s>', '<unk>', 'has', 'this', '<unk>', '.', '</s>']\n",
      "['<s>', '<unk>', 'has', 'the', '<unk>', '.', '</s>']\n",
      "['<s>', 'So', ',', '</s>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<s>', '<unk>', 'has', 'this', '<unk>', '.', '</s>', '<pad>']\n",
      "['<s>', '<unk>', 'has', 'the', '<unk>', '.', '</s>', '<pad>']\n",
      "['<s>', 'So', ',', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<s>', '<unk>', 'has', 'this', '<unk>', '.', '</s>', '<pad>', '<pad>']\n",
      "['<s>', '<unk>', 'has', 'the', '<unk>', '.', '</s>', '<pad>', '<pad>']\n",
      "['<s>', 'So', ',', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "['<s>', '<unk>', 'has', 'this', '<unk>', '.', '</s>', '<pad>', '<pad>', '<pad>']\n",
      "['<s>', '<unk>', 'has', 'the', '<unk>', '.', '</s>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "val_iter.batch_size = 64\n",
    "for batch in val_iter:\n",
    "    break\n",
    "pred_beam = lstma.translate_beam(batch.src.transpose(0,1).cuda(),print_beam_row=5) \n",
    "#Turn print_beam_row to -1 to disable printing. \n",
    "#Turn it to row number that you want to see evolve in beam search.Works only in ipython for now. Form making it work, uncomment\n",
    "#code in the above cell and use that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_iter.batch_size = 64\n",
    "for batch in val_iter:\n",
    "    break\n",
    "pred = lstma.translate(batch.src.transpose(0,1).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TEST BEAM PREDICTION - remember beam is of dimension - batch size * beam size . so pred_beam[a][b] will give ath element \n",
    "\n",
    "in the batch and its bth beam value. b= 0 will be the most likely option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beam's best prediction(Change 0 to other elem for other predicitons) : \n",
      "['<s>', 'So', ',', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Greedy prediction : \n",
      "['<s>', '<unk>', 'has', 'this', '.', '</s>', '<pad>', '<pad>', '<pad>']\n",
      "actual text\n",
      "['<s>', 'So', 'planning', 'has', 'this', 'blind', 'spot', '.', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "batch_elem = 5\n",
    "print(\"beam's best prediction(Change 0 to other elem for other predicitons) : \")\n",
    "print([EN.vocab.itos[int(x)] for x in pred_beam[batch_elem][0]])\n",
    "print(\"Greedy prediction : \")\n",
    "print([EN.vocab.itos[int(x)] for x in pred[batch_elem].data.cpu().numpy()])\n",
    "print(\"actual text\")\n",
    "print([EN.vocab.itos[x] for x in batch.trg.transpose(0,1)[batch_elem].data.numpy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
