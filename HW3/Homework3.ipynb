{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3: Neural Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework you will build a full neural machine translation system using an attention-based encoder-decoder network to translate from German to English. The encoder-decoder network with attention forms the backbone of many current text generation systems. See [Neural Machine Translation and Sequence-to-sequence Models: A Tutorial](https://arxiv.org/pdf/1703.01619.pdf) for an excellent tutorial that also contains many modern advances.\n",
    "\n",
    "## Goals\n",
    "\n",
    "\n",
    "1. Build a non-attentional baseline model (pure seq2seq as in [ref](https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)). \n",
    "2. Incorporate attention into the baseline model ([ref](https://arxiv.org/abs/1409.0473) but with dot-product attention as in class notes).\n",
    "3. Implement beam search: review/tutorial [here](http://www.phontron.com/slides/nlp-programming-en-13-search.pdf)\n",
    "4. Visualize the attention distribution for a few examples. \n",
    "\n",
    "Consult the papers provided for hyperparameters, and the course notes for formal definitions.\n",
    "\n",
    "This will be the most time-consuming assignment in terms of difficulty/training time, so we recommend that you get started early!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This notebook provides a working definition of the setup of the problem itself. Feel free to construct your models inline, or use an external setup (preferred) to build your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text text processing library and methods for pretrained word embeddings\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to process the raw data using a tokenizer. We are going to be using spacy, which can be installed via:  \n",
    "  `[sudo] pip install spacy`  \n",
    "  \n",
    "Tokenizers for English/German can be installed via:  \n",
    "  `[sudo] python -m spacy download en`  \n",
    "  `[sudo] python -m spacy download de`\n",
    "  \n",
    "This isn't *strictly* necessary, and you can use your own tokenization rules if you prefer (e.g. a simple `split()` in addition to some rules to acccount for punctuation), but we recommend sticking to the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we need to add the beginning-of-sentence token `<s>` and the end-of-sentence token `</s>` to the \n",
    "target so we know when to begin/end translating. We do not need to do this on the source side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "DE = data.Field(tokenize=tokenize_de)\n",
    "EN = data.Field(tokenize=tokenize_en, init_token = BOS_WORD, eos_token = EOS_WORD) # only target needs BOS/EOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the data. This may take a few minutes.\n",
    "\n",
    "**While this dataset of 200K sentence pairs is relatively small compared to others, it will still take some time to train. So we are going to be only working with sentences of length at most 20 for this homework. Please train only on this reduced dataset for this homework.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': <torchtext.data.field.Field object at 0x7ff63e6d21d0>, 'trg': <torchtext.data.field.Field object at 0x7ff63e6d2780>}\n",
      "119076\n",
      "{'src': ['David', 'Gallo', ':', 'Das', 'ist', 'Bill', 'Lange', '.', 'Ich', 'bin', 'Dave', 'Gallo', '.'], 'trg': ['David', 'Gallo', ':', 'This', 'is', 'Bill', 'Lange', '.', 'I', \"'m\", 'Dave', 'Gallo', '.']}\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 20\n",
    "train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(DE, EN), \n",
    "                                         filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
    "                                         len(vars(x)['trg']) <= MAX_LEN)\n",
    "print(train.fields)\n",
    "print(len(train))\n",
    "print(vars(train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the vocabulary and convert the text corpus into indices. We are going to be replacing tokens that occurred less than 5 times with `<unk>` tokens, and take the rest as our vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 113253), (',', 67237), ('ist', 24189), ('die', 23778), ('das', 17102), ('der', 15727), ('und', 15622), ('Sie', 15085), ('es', 13197), ('ich', 12946)]\n",
      "Size of German vocab 13353\n",
      "[('.', 113433), (',', 59512), ('the', 46029), ('to', 29177), ('a', 27548), ('of', 26794), ('I', 24887), ('is', 21775), (\"'s\", 20630), ('that', 19814)]\n",
      "Size of English vocab 11560\n",
      "2 3\n"
     ]
    }
   ],
   "source": [
    "MIN_FREQ = 5\n",
    "DE.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "EN.build_vocab(train.trg, min_freq=MIN_FREQ)\n",
    "print(DE.vocab.freqs.most_common(10))\n",
    "print(\"Size of German vocab\", len(DE.vocab))\n",
    "print(EN.vocab.freqs.most_common(10))\n",
    "print(\"Size of English vocab\", len(EN.vocab))\n",
    "print(EN.vocab.stoi[\"<s>\"], EN.vocab.stoi[\"</s>\"]) #vocab index for <s>, </s>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split our data into batches as usual. Batching for MT is slightly tricky because source/target will be of different lengths. Fortunately, `torchtext` lets you do this by allowing you to pass in a `sort_key` function. This will minimizing the amount of padding on the source side, but since there is still some padding you will inadvertendly \"attend\" to these padding tokens. \n",
    "\n",
    "One way to get rid of padding is to pass a binary `mask` vector to your attention module so its attention score (before the softmax) is minus infinity for the padding token. Another way (which is how we do it for our projects, e.g. opennmt) is to manually sort data into batches so that each batch has exactly the same source length (this means that some batches will be less than the desired batch size, though).\n",
    "\n",
    "However, for this homework padding won't matter too much, so it's fine to ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=BATCH_SIZE, device=-1,\n",
    "                                                  repeat=False, sort_key=lambda x: len(x.src))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to see that the BOS/EOS token is indeed appended to the target (English) sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(\"Source\")\n",
    "print(batch.src)\n",
    "print(\"Target\")\n",
    "print(batch.trg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! Now that we've processed the data, we are ready to begin modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "Now it is your turn to build the models described at the top of the assignment. \n",
    "\n",
    "When a model is trained, use the following test function to produce predictions, and then upload to the kaggle competition: https://www.kaggle.com/c/cs287-hw3-s18/\n",
    "\n",
    "For the final Kaggle test, we will provide the source sentence, and you are to predict the **first three words of the target sentence**. The source sentence can be found under `source_test.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head source_test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to HW1, you are to predict the 100 most probable 3-gram that will begin the target sentence. The submission format will be as follows, where each word in the 3-gram will be separated by \"|\", and each 3-gram will be separated by space. For example, here is what an example submission might look like with 5 most-likely 3-grams (instead of 100)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "id,word\n",
    "1,Newspapers|talk|about When|I|was Researchers|call|the Twentysomethings|like|Alex But|before|long\n",
    "2,That|'s|what Newspapers|talk|about You|have|robbed It|'s|realizing My|parents|wanted\n",
    "3,We|forget|how We|think|about Proust|actually|links Does|any|other This|is|something\n",
    "4,But|what|do And|it|'s They|'re|on My|name|is It|only|happens\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you print out your data, you will need to escape quotes and commas with the following command so that Kaggle does not complain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escape(l):\n",
    "    return l.replace(\"\\\"\", \"<quote>\").replace(\",\", \"<comma>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should perform your hyperparameter search/early stopping/write-up based on perplexity, not the above metric. (In practice, people use a metric called [BLEU](https://www.aclweb.org/anthology/P02-1040.pdf), which is roughly a geometric average of 1-gram, 2-gram, 3-gram, 4-gram precision, with a brevity penalty for producing translations that are too short.)\n",
    "\n",
    "Finally, as always please put up a (short) write-up following the template provided in the repository:  https://github.com/harvard-ml-courses/cs287-s18/blob/master/template/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../HW3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "os.chdir('../HW3')  # so that there is not any import bug in case HW2 is not already the working directory\n",
    "from utils import *\n",
    "from const import *\n",
    "import argparse\n",
    "import torch as t\n",
    "from process_params import check_args, get_params\n",
    "from const import *\n",
    "from data_process import generate_iterators\n",
    "from utils import *\n",
    "t.manual_seed(1)\n",
    "\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "from utils import variable\n",
    "from const import *\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import spacy\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import pickle\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMA(t.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of `Neural Machine Translation by Jointly Learning to Align and Translate`\n",
    "    https://arxiv.org/abs/1409.0473\n",
    "\n",
    "    NOTE THAT ITS INPUT SHOULD HAVE THE BATCH SIZE FIRST !!!!!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, source_embeddings=None, target_embeddings=None):\n",
    "        super(LSTMA, self).__init__()\n",
    "        print(\"Initializing LSTMA\")\n",
    "        self.cuda_flag = params.get('cuda', CUDA_DEFAULT)\n",
    "        self.model_str = 'LSTMA'\n",
    "        self.params = params\n",
    "\n",
    "        # Initialize hyperparams.\n",
    "        self.hidden_dim = params.get('hidden_dim', 100)\n",
    "        self.batch_size = params.get('batch_size', 32)\n",
    "        try:\n",
    "            # if you provide pre-trained embeddings for target/source, they should have the same embedding dim\n",
    "            assert source_embeddings.size(1) == target_embeddings.size(1)\n",
    "            self.embedding_dim = source_embeddings.size(1)\n",
    "            self.source_vocab_size = params.get('source_vocab_size')\n",
    "            self.target_vocab_size = params.get('target_vocab_size')\n",
    "        except:\n",
    "            # if you dont provide a pre-trained embedding, you have to provide these\n",
    "            self.embedding_dim = params.get('embedding_dim')\n",
    "            self.source_vocab_size = params.get('source_vocab_size')\n",
    "            self.target_vocab_size = params.get('target_vocab_size')\n",
    "            assert self.embedding_dim is not None and self.source_vocab_size is not None and self.target_vocab_size is not None\n",
    "        self.output_size = self.target_vocab_size\n",
    "        self.num_layers = params.get('num_layers', 1)\n",
    "        self.dropout = params.get('dropout', 0.5)\n",
    "        self.embed_dropout = params.get('embed_dropout')\n",
    "        self.train_embedding = params.get('train_embedding', True)\n",
    "\n",
    "        # Initialize embeddings. Static embeddings for now.\n",
    "        self.source_embeddings = t.nn.Embedding(self.source_vocab_size, self.embedding_dim)\n",
    "        self.target_embeddings = t.nn.Embedding(self.target_vocab_size, self.embedding_dim)\n",
    "        if source_embeddings is not None:\n",
    "            self.source_embeddings.weight = t.nn.Parameter(source_embeddings, requires_grad=self.train_embedding)\n",
    "        if target_embeddings is not None:\n",
    "            self.target_embeddings.weight = t.nn.Parameter(target_embeddings, requires_grad=self.train_embedding)\n",
    "\n",
    "        # Initialize network modules.\n",
    "        # note that the encoder is a BiLSTM. The output is modified by the fact that the hidden dim is doubled, and if you set\n",
    "        # the number of layers to L, there will actually be 2L layers (the forward ones and the backward ones). Consequently the first\n",
    "        # dimension of the hidden outputs of the forward pass (the 2nd output in the tuple) will be a tuple of\n",
    "        # 2 tensors having as first dim twice the hidden dim you set\n",
    "        self.encoder_rnn = t.nn.LSTM(self.embedding_dim, self.hidden_dim // 2, dropout=self.dropout, num_layers=self.num_layers, bidirectional=True, batch_first=True)\n",
    "        self.decoder_rnn = t.nn.LSTM(self.embedding_dim, self.hidden_dim, dropout=self.dropout, num_layers=self.num_layers, batch_first=True)\n",
    "        self.hidden_dec_initializer = t.nn.Linear(self.hidden_dim // 2, self.num_layers * self.hidden_dim)\n",
    "        self.hidden2out = t.nn.Linear(self.hidden_dim * 2, self.output_size)\n",
    "        if self.embed_dropout:\n",
    "            self.dropout_1s = t.nn.Dropout(self.dropout)\n",
    "            self.dropout_1t = t.nn.Dropout(self.dropout)\n",
    "        self.dropout_2 = t.nn.Dropout(self.dropout)\n",
    "        self.lsm = nn.LogSoftmax()\n",
    "\n",
    "        self.beam_size = params.get('beam_size', 3)\n",
    "        self.max_beam_depth = params.get('max_beam_depth', 20)\n",
    "\n",
    "        if self.cuda_flag:\n",
    "            self = self.cuda()\n",
    "\n",
    "    def init_hidden(self, data, type, batch_size=None):\n",
    "        \"\"\"\n",
    "        Initialize the hidden state, either for the encoder or the decoder\n",
    "\n",
    "        For type=`enc`, it should just be initialized with 0s\n",
    "        For type=`dec`, it should be initialized with tanh(W h1_backward) (see page 13 of the paper, last paragraph)\n",
    "\n",
    "        `data` is either something you initialize the hidden state with, or None\n",
    "        \"\"\"\n",
    "        bs = batch_size if batch_size is not None else self.batch_size\n",
    "        if type == 'dec':\n",
    "            # in that case, `data` is the output of the encoder\n",
    "            # data[:, :1, self.hidden_dim // 2:]\n",
    "            # `:` for the whole batch\n",
    "            # `:1` because you want the hidden state of the first time step (see paper, they use backward(h1))\n",
    "            # but also `self.hidden_dim // 2:`, because you want the backward part only (the last coefficients)\n",
    "            h = F.tanh(self.hidden_dec_initializer(data[:, :1, self.hidden_dim // 2:]))  # the last hdim/2 weights correspond to the backward layer(s)\n",
    "            h = h.transpose(1, 0)\n",
    "            h = t.cat(t.split(h, self.hidden_dim, dim=2), 0)\n",
    "            return (\n",
    "                h,\n",
    "                variable(np.zeros((self.num_layers, bs, self.hidden_dim)), cuda=self.cuda_flag)\n",
    "            )\n",
    "        elif type == 'enc':\n",
    "            # in that case data is None\n",
    "            return tuple((\n",
    "                variable(np.zeros((self.num_layers * 2, bs, self.hidden_dim // 2)), cuda=self.cuda_flag),\n",
    "                variable(np.zeros((self.num_layers * 2, bs, self.hidden_dim // 2)), cuda=self.cuda_flag)\n",
    "            ))\n",
    "        else:\n",
    "            raise ValueError('the type should be either `dec` or `enc`')\n",
    "\n",
    "    def forward(self, x_source, x_target, return_attn=False):\n",
    "        # EMBEDDING\n",
    "        embedded_x_source = self.source_embeddings(x_source)\n",
    "        embedded_x_target = self.target_embeddings(x_target[:, :-1])  # don't make a prediction for the word following the last one\n",
    "        if self.embed_dropout:\n",
    "            embedded_x_source = self.dropout_1s(embedded_x_source)\n",
    "            embedded_x_target = self.dropout_1t(embedded_x_target)\n",
    "\n",
    "        # RECURRENT\n",
    "        hidden = self.init_hidden(None, 'enc', x_source.size(0))\n",
    "        enc_out, _ = self.encoder_rnn(embedded_x_source, hidden)\n",
    "        hidden = self.init_hidden(enc_out, 'dec', x_source.size(0))\n",
    "        dec_out, _ = self.decoder_rnn(embedded_x_target, hidden)\n",
    "\n",
    "        # ATTENTION\n",
    "        scores = t.bmm(enc_out, dec_out.transpose(1, 2))  # this will be a batch x source_len x target_len\n",
    "        attn_dist = F.softmax(scores, dim=1)  # batch x source_len x target_len\n",
    "        context = t.bmm(attn_dist.permute(0, 2, 1), enc_out)  # batch x target_len x hidden_dim\n",
    "\n",
    "        # OUTPUT\n",
    "        # concatenate the output of the decoder and the context and apply nonlinearity\n",
    "        pred = F.tanh(t.cat([dec_out, context], -1))\n",
    "        pred = self.dropout_2(pred)  # batch x target_len x 2 hdim\n",
    "        pred = self.hidden2out(pred)\n",
    "\n",
    "        if return_attn:\n",
    "            return pred, attn_dist\n",
    "        else:\n",
    "            return pred\n",
    "\n",
    "    def translate(self, x_source):\n",
    "        self.eval()\n",
    "\n",
    "        # EMBEDDING\n",
    "        embedded_x_source = self.source_embeddings(x_source)\n",
    "        if self.embed_dropout:\n",
    "            embedded_x_source = self.dropout_1s(embedded_x_source)\n",
    "\n",
    "        # RECURRENT\n",
    "        hidden = self.init_hidden(None, 'enc', x_source.size(0))\n",
    "        enc_out, _ = self.encoder_rnn(embedded_x_source, hidden)\n",
    "        hidden = self.init_hidden(enc_out, 'dec', x_source.size(0))\n",
    "        x_target = (SOS_TOKEN * t.ones(x_source.size(0), 1)).long()  # `2` is the SOS token (<s>)\n",
    "        x_target = variable(x_target, to_float=False, cuda=self.cuda_flag)\n",
    "        count_eos = 0\n",
    "        time = 0\n",
    "        while count_eos < x_source.size(0):\n",
    "            embedded_x_target = self.target_embeddings(x_target)\n",
    "            dec_out, hidden = self.decoder_rnn(embedded_x_target, hidden)\n",
    "            hidden = hidden[0].detach(), hidden[1].detach()\n",
    "            dec_out = dec_out[:, time:time + 1, :].detach()\n",
    "\n",
    "            # ATTENTION\n",
    "            scores = t.bmm(enc_out, dec_out.transpose(1, 2))  # this will be a batch x source_len x target_len\n",
    "            try:\n",
    "                attn_dist = F.softmax(scores, dim=1)  # batch x source_len x target_len\n",
    "            except:\n",
    "                attn_dist = F.softmax(scores.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "            context = t.bmm(attn_dist.permute(0, 2, 1), enc_out)  # batch x target_len x hidden_dim\n",
    "\n",
    "            # OUTPUT\n",
    "            # concatenate the output of the decoder and the context and apply nonlinearity\n",
    "            pred = F.tanh(t.cat([dec_out, context], -1))\n",
    "            pred = self.dropout_2(pred)  # batch x target_len x 2 hdim\n",
    "            pred = self.hidden2out(pred).detach()\n",
    "            x_target = t.cat([x_target, pred.max(2)[1]], 1).detach()\n",
    "\n",
    "            # should you stop ?\n",
    "            count_eos += t.sum((pred.max(2)[1] == EOS_TOKEN).long()).data.cpu().numpy()[0]  # `3` is the EOS token\n",
    "            time += 1\n",
    "        return x_target\n",
    "\n",
    "    def translate_beam(self, x_source,print_beam_row=-1):\n",
    "        self.eval()\n",
    "\n",
    "        # EMBEDDING\n",
    "        embedded_x_source = self.source_embeddings(x_source)\n",
    "        if self.embed_dropout:\n",
    "            embedded_x_source = self.dropout_1s(embedded_x_source)\n",
    "\n",
    "        terminate_beam = False\n",
    "        batch_size = x_source.size(0)\n",
    "\n",
    "        # RECURRENT\n",
    "        hidden = self.init_hidden(None, 'enc', x_source.size(0))\n",
    "        enc_out, _ = self.encoder_rnn(embedded_x_source, hidden)\n",
    "        \n",
    "        #One hidden for each beam element.\n",
    "        hidden = []\n",
    "        for i in range(self.beam_size):\n",
    "            hidden.append(self.init_hidden(enc_out, 'dec', x_source.size(0)))\n",
    "            \n",
    "        x_target = SOS_TOKEN * np.ones((x_source.size(0), 1))  # `2` is the SOS token (<s>)\n",
    "        count_eos = 0\n",
    "        time = 0\n",
    "\n",
    "        # INIT SOME STUFF.\n",
    "        self.beam = np.array(x_target)\n",
    "        self.beam_scores = np.zeros((batch_size, 1))\n",
    "\n",
    "        while not terminate_beam and time < self.max_beam_depth:\n",
    "            collective_children = np.array([])\n",
    "            collective_scores = np.array([])\n",
    "\n",
    "            #import pdb; pdb.set_trace()   \n",
    "            if len(self.beam.shape) < 3:\n",
    "                reshaped_beam = self.beam.transpose((1,0))            \n",
    "            else:\n",
    "                reshaped_beam = np.transpose(self.beam,(1,0,2))                \n",
    "             \n",
    "            for it, elem in enumerate(reshaped_beam):\n",
    "                elem = t.from_numpy(elem).long()\n",
    "                x_target = elem.contiguous().view(self.batch_size, -1)\n",
    "                x_target = variable(x_target, to_float=False, cuda=self.cuda_flag).long()\n",
    "                embedded_x_target = self.target_embeddings(x_target)\n",
    "                dec_out, hidden_out = self.decoder_rnn(embedded_x_target, hidden[it])\n",
    "                hidden[it] = hidden_out[0].detach(), hidden_out[1].detach()\n",
    "                dec_out = dec_out[:, time:time + 1, :].detach()\n",
    "\n",
    "                # ATTENTION\n",
    "                scores = t.bmm(enc_out, dec_out.transpose(1, 2))  # this will be a batch x source_len x target_len\n",
    "                try:\n",
    "                    attn_dist = F.softmax(scores, dim=1)  # batch x source_len x target_len\n",
    "                except:\n",
    "                    attn_dist = F.softmax(scores.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "                context = t.bmm(attn_dist.permute(0, 2, 1), enc_out)  # batch x target_len x hidden_dim\n",
    "\n",
    "                # OUTPUT\n",
    "                # concatenate the output of the decoder and the context and apply nonlinearity\n",
    "                pred = F.tanh(t.cat([dec_out, context], -1))\n",
    "                pred = self.dropout_2(pred)  # batch x target_len x 2 hdim\n",
    "                pred = self.hidden2out(pred).detach()\n",
    "                pred = self.lsm(pred.view(batch_size,-1)).detach()\n",
    "\n",
    "                topk = t.topk(pred, self.beam_size, dim=1)\n",
    "                top_k_indices, top_k_scores = topk[1], topk[0]\n",
    "                top_k_indices = top_k_indices.transpose(0,1)\n",
    "                top_k_scores = top_k_scores.transpose(0,1)\n",
    "                \n",
    "                #import pdb; pdb.set_trace()\n",
    "                \n",
    "                for new_word_batch, new_score_batch in zip(top_k_indices, top_k_scores):\n",
    "                    new_word_batch = new_word_batch.contiguous().view(batch_size,1)\n",
    "                    new_score_batch = new_score_batch.contiguous().view(batch_size,1)\n",
    "                     \n",
    "                    new_child_batch = t.cat([x_target, new_word_batch], 1).detach()\n",
    "\n",
    "                    batch_parent_score = self.beam_scores[:, it].reshape((self.batch_size, 1))\n",
    "                    batch_acc_score = batch_parent_score + new_score_batch.data.cpu().numpy()\n",
    "\n",
    "                    if len(collective_children) > 0:\n",
    "                        collective_children = np.hstack((collective_children, new_child_batch.data.cpu().numpy()))\n",
    "                        # Add the corresponding beam element's score with the new score and stack it.\n",
    "                        collective_scores = np.hstack((collective_scores, batch_acc_score))\n",
    "                    else:\n",
    "                        collective_children, collective_scores = new_child_batch.data.cpu().numpy(), batch_acc_score\n",
    "\n",
    "\n",
    "            current_beam_length = self.beam.shape[1]            \n",
    "            collective_children = collective_children.reshape((batch_size, current_beam_length * self.beam_size,\n",
    "                                                               int(collective_children.shape[1] /\n",
    "                                                                   current_beam_length / self.beam_size)\n",
    "                                                               ))\n",
    "\n",
    "            if collective_children.shape[1] == self.beam_size:  # Happens the first time.\n",
    "                self.beam = collective_children\n",
    "                self.beam_scores = collective_scores\n",
    "                if print_beam_row > -1:\n",
    "                    for l in range(self.beam_size):\n",
    "                        print([EN.vocab.itos[int(x)] for x in self.beam[print_beam_row,int(l)]])\n",
    "            else:\n",
    "                self.beam = deepcopy(np.zeros((batch_size, self.beam_size, collective_children.shape[2])))\n",
    "                #import pdb; pdb.set_trace()\n",
    "                for i in range(batch_size):\n",
    "                    # Since argsort gives ascending order\n",
    "                    best_scores_indices = np.argsort(-1 * collective_scores[i])[:self.beam_size]\n",
    "                    for key, index in enumerate(best_scores_indices):\n",
    "                        self.beam[i][key][:] = collective_children[i][index]\n",
    "                        self.beam_scores[i][key] = collective_scores[i][index]\n",
    "                if print_beam_row > -1:\n",
    "                    for l in range(self.beam_size):\n",
    "                        print([EN.vocab.itos[int(x)] for x in self.beam[print_beam_row,int(l)]])\n",
    "\n",
    "            terminate_beam = True\n",
    "\n",
    "            for x in self.beam:\n",
    "                for c in x:\n",
    "                    if EOS_TOKEN not in c:\n",
    "                        terminate_beam = False\n",
    "                        break\n",
    "                if not terminate_beam:\n",
    "                    break\n",
    "            \n",
    "            \n",
    "            assert (self.beam.shape == (batch_size, self.beam_size, time + 2))\n",
    "\n",
    "            time += 1\n",
    "            #print(time)\n",
    "        return self.beam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMF(t.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of `Neural Machine Translation by Jointly Learning to Align and Translate`\n",
    "    https://arxiv.org/abs/1409.0473\n",
    "\n",
    "    NOTE THAT ITS INPUT SHOULD HAVE THE BATCH SIZE FIRST !!!!!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, source_embeddings=None, target_embeddings=None):\n",
    "        super(LSTMF, self).__init__()\n",
    "        print(\"Initializing LSTMF\")\n",
    "        self.cuda_flag = params.get('cuda', CUDA_DEFAULT)\n",
    "        self.model_str = 'LSTMF'\n",
    "        self.params = params\n",
    "\n",
    "        # Initialize hyperparams.\n",
    "        self.hidden_dim = params.get('hidden_dim', 100)\n",
    "        self.batch_size = params.get('batch_size', 32)\n",
    "        self.dropout = params.get('dropout', 0.5)\n",
    "        self.embed_dropout = params.get('embed_dropout')\n",
    "        self.initialize_embeddings(params, source_embeddings, target_embeddings)\n",
    "        self.output_size = self.target_vocab_size\n",
    "        assert self.hidden_dim == self.embedding_dim\n",
    "\n",
    "        # Initialize network modules.\n",
    "        self.encoder_rnn1 = t.nn.LSTM(self.embedding_dim, self.hidden_dim // 2, dropout=self.dropout, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.encoder_rnn2 = t.nn.LSTM(self.embedding_dim, self.hidden_dim, dropout=self.dropout, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        self.decoder_rnn1 = t.nn.LSTM(self.embedding_dim, self.hidden_dim, dropout=self.dropout, num_layers=1, batch_first=True)\n",
    "        self.decoder_rnn2 = t.nn.LSTM(self.embedding_dim, self.hidden_dim, dropout=self.dropout, num_layers=1, batch_first=True)\n",
    "        self.hidden_dec_initializer = t.nn.Linear(self.hidden_dim // 2, 2 * self.hidden_dim)\n",
    "        self.hidden2out = t.nn.Linear(self.hidden_dim * 2, self.output_size)\n",
    "        if self.embed_dropout:\n",
    "            self.dropout_1s = t.nn.Dropout(self.dropout)\n",
    "            self.dropout_1t = t.nn.Dropout(self.dropout)\n",
    "        self.dropout_1_enc = t.nn.Dropout(self.dropout)\n",
    "        self.dropout_1_dec = t.nn.Dropout(self.dropout)\n",
    "        self.dropout_2 = t.nn.Dropout(self.dropout)\n",
    "        self.linear_enc = t.nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.linear_dec = t.nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.linear_attn = t.nn.Linear(self.hidden_dim, 1, bias=False)\n",
    "        self.lsm = nn.LogSoftmax()\n",
    "\n",
    "        self.beam_size = params.get('beam_size', 3)\n",
    "        self.max_beam_depth = params.get('max_beam_depth', 20)\n",
    "\n",
    "        if self.cuda_flag:\n",
    "            self = self.cuda()\n",
    "\n",
    "    def initialize_embeddings(self, params, source_embeddings, target_embeddings):\n",
    "        try:\n",
    "            # if you provide pre-trained embeddings for target/source, they should have the same embedding dim\n",
    "            assert source_embeddings.size(1) == target_embeddings.size(1)\n",
    "            self.embedding_dim = source_embeddings.size(1)\n",
    "            self.source_vocab_size = params.get('source_vocab_size')\n",
    "            self.target_vocab_size = params.get('target_vocab_size')\n",
    "        except:\n",
    "            # if you dont provide a pre-trained embedding, you have to provide these\n",
    "            self.embedding_dim = params.get('embedding_dim')\n",
    "            self.source_vocab_size = params.get('source_vocab_size')\n",
    "            self.target_vocab_size = params.get('target_vocab_size')\n",
    "            assert self.embedding_dim is not None and self.source_vocab_size is not None and self.target_vocab_size is not None\n",
    "\n",
    "        self.train_embedding = params.get('train_embedding', True)\n",
    "\n",
    "        # Initialize embeddings. Static embeddings for now.\n",
    "        self.source_embeddings = t.nn.Embedding(self.source_vocab_size, self.embedding_dim)\n",
    "        self.target_embeddings = t.nn.Embedding(self.target_vocab_size, self.embedding_dim)\n",
    "        if source_embeddings is not None:\n",
    "            self.source_embeddings.weight = t.nn.Parameter(source_embeddings, requires_grad=self.train_embedding)\n",
    "        if target_embeddings is not None:\n",
    "            self.target_embeddings.weight = t.nn.Parameter(target_embeddings, requires_grad=self.train_embedding)\n",
    "\n",
    "    def init_hidden(self, data, type, batch_size=None):\n",
    "        \"\"\"\n",
    "        Initialize the hidden state, either for the encoder or the decoder\n",
    "\n",
    "        For type=`enc`, it should just be initialized with 0s\n",
    "        For type=`dec`, it should be initialized with tanh(W h1_backward) (see page 13 of the paper, last paragraph)\n",
    "\n",
    "        `data` is either something you initialize the hidden state with, or None\n",
    "        \"\"\"\n",
    "        bs = batch_size if batch_size is not None else self.batch_size\n",
    "        if type == 'dec':\n",
    "            # in that case, `data` is the output of the encoder\n",
    "            # data[:, :1, self.hidden_dim // 2:]\n",
    "            # `:` for the whole batch\n",
    "            # `:1` because you want the hidden state of the first time step (see paper, they use backward(h1))\n",
    "            # but also `self.hidden_dim // 2:`, because you want the backward part only (the last coefficients)\n",
    "            h = F.tanh(self.hidden_dec_initializer(data[:, -1:, self.hidden_dim // 2:]))  # the last hdim/2 weights correspond to the backward layer(s)\n",
    "            h = h.transpose(1, 0)\n",
    "            h = t.cat(t.split(h, self.hidden_dim, dim=2), 0)\n",
    "            return (\n",
    "                h,\n",
    "                variable(np.zeros((2, bs, self.hidden_dim)), cuda=self.cuda_flag)\n",
    "            )\n",
    "        elif type == 'enc1':\n",
    "            # in that case data is None\n",
    "            return tuple((\n",
    "                variable(np.zeros((2, bs, self.hidden_dim // 2)), cuda=self.cuda_flag),\n",
    "                variable(np.zeros((2, bs, self.hidden_dim // 2)), cuda=self.cuda_flag)\n",
    "            ))\n",
    "        elif type == 'enc2':\n",
    "            # in that case data is None\n",
    "            return tuple((\n",
    "                variable(np.zeros((1, bs, self.hidden_dim)), cuda=self.cuda_flag),\n",
    "                variable(np.zeros((1, bs, self.hidden_dim)), cuda=self.cuda_flag)\n",
    "            ))\n",
    "        else:\n",
    "            raise ValueError('the type should be either `dec` or `enc`')\n",
    "\n",
    "    def forward(self, x_source, x_target, return_attn=False):\n",
    "        batch_size = x_source.size(0)\n",
    "        src_len = x_source.size(1)\n",
    "        trg_len = x_target.size(1) - 1\n",
    "\n",
    "        # EMBEDDING\n",
    "        embedded_x_source = self.source_embeddings(x_source)\n",
    "        embedded_x_target = self.target_embeddings(x_target[:, :-1])  # don't make a prediction for the word following the last one\n",
    "        if self.embed_dropout:\n",
    "            embedded_x_source = self.dropout_1s(embedded_x_source)\n",
    "            embedded_x_target = self.dropout_1t(embedded_x_target)\n",
    "\n",
    "        # RECURRENT: 2 layers of encoder and 2 layers of decoder. There is dropout inbetween layers, and skip connections as well\n",
    "        # encoder\n",
    "        hidden1 = self.init_hidden(None, 'enc1', batch_size)\n",
    "        hidden2 = self.init_hidden(None, 'enc2', batch_size)\n",
    "        enc_out, _ = self.encoder_rnn1(embedded_x_source, hidden1)\n",
    "        enc_out, _ = self.encoder_rnn2(self.dropout_1_enc(embedded_x_source + enc_out), hidden2)  # skip connection + dropout\n",
    "        # decoder\n",
    "        hidden12 = self.init_hidden(enc_out, 'dec', batch_size)\n",
    "        hidden1 = hidden12[0][:1, :, :], hidden12[1][:1, :, :]\n",
    "        hidden2 = hidden12[0][1:, :, :], hidden12[1][1:, :, :]\n",
    "        dec_out, _ = self.decoder_rnn1(embedded_x_target, hidden1)\n",
    "        dec_out, _ = self.decoder_rnn2(self.dropout_1_dec(embedded_x_target + dec_out), hidden2)\n",
    "\n",
    "        # ATTENTION: just like in the paper\n",
    "        scores = self.linear_attn(F.tanh(\n",
    "            self.linear_enc(enc_out).unsqueeze(2).expand(batch_size, src_len, trg_len, self.hidden_dim) +\n",
    "            self.linear_dec(dec_out).unsqueeze(1).expand(batch_size, src_len, trg_len, self.hidden_dim)\n",
    "        )).squeeze(3)\n",
    "        attn_dist = F.softmax(scores, dim=1)  # batch x source_len x target_len\n",
    "        context = t.bmm(attn_dist.permute(0, 2, 1), enc_out)  # batch x target_len x hidden_dim\n",
    "\n",
    "        # OUTPUT\n",
    "        # concatenate the output of the decoder and the context and apply nonlinearity\n",
    "        pred = F.tanh(t.cat([dec_out, context], -1))\n",
    "        pred = self.dropout_2(pred)  # batch x target_len x 2 hdim\n",
    "        pred = self.hidden2out(pred)\n",
    "\n",
    "        if return_attn:\n",
    "            return pred, attn_dist\n",
    "        else:\n",
    "            return pred\n",
    "\n",
    "    def translate(self, x_source):\n",
    "        batch_size = x_source.size(0)\n",
    "        src_len = x_source.size(1)\n",
    "        self.eval()\n",
    "\n",
    "        # EMBEDDING\n",
    "        embedded_x_source = self.source_embeddings(x_source)\n",
    "        if self.embed_dropout:\n",
    "            embedded_x_source = self.dropout_1s(embedded_x_source)\n",
    "\n",
    "        # RECURRENT\n",
    "        hidden1 = self.init_hidden(None, 'enc1', batch_size)\n",
    "        hidden2 = self.init_hidden(None, 'enc2', batch_size)\n",
    "        enc_out, _ = self.encoder_rnn1(embedded_x_source, hidden1)\n",
    "        enc_out, _ = self.encoder_rnn2(self.dropout_1_enc(embedded_x_source + enc_out), hidden2)  # skip connection + dropout\n",
    "        x_target = (SOS_TOKEN * t.ones(x_source.size(0), 1)).long()  # `2` is the SOS token (<s>)\n",
    "        x_target = variable(x_target, to_float=False, cuda=self.cuda_flag)\n",
    "        count_eos = 0\n",
    "        time = 0\n",
    "        while count_eos < x_source.size(0):\n",
    "            embedded_x_target = self.target_embeddings(x_target)\n",
    "            hidden12 = self.init_hidden(enc_out, 'dec', batch_size)\n",
    "            hidden1 = hidden12[0][:1, :, :], hidden12[1][:1, :, :]\n",
    "            hidden2 = hidden12[0][1:, :, :], hidden12[1][1:, :, :]\n",
    "            dec_out, _ = self.decoder_rnn1(embedded_x_target, hidden1)\n",
    "            dec_out, _ = self.decoder_rnn2(self.dropout_1_dec(embedded_x_target + dec_out), hidden2)\n",
    "            dec_out = dec_out[:, time:time + 1, :].detach()\n",
    "\n",
    "            # ATTENTION: just like in the paper\n",
    "            scores = self.linear_attn(F.tanh(\n",
    "                self.linear_enc(enc_out).unsqueeze(2).expand(batch_size, src_len, 1, self.hidden_dim) +\n",
    "                self.linear_dec(dec_out).unsqueeze(1).expand(batch_size, src_len, 1, self.hidden_dim)\n",
    "            )).squeeze(3)\n",
    "            attn_dist = F.softmax(scores, dim=1)  # batch x source_len x target_len\n",
    "            context = t.bmm(attn_dist.permute(0, 2, 1), enc_out)  # batch x target_len x hidden_dim\n",
    "\n",
    "            # OUTPUT\n",
    "            # concatenate the output of the decoder and the context and apply nonlinearity\n",
    "            pred = F.tanh(t.cat([dec_out, context], -1))\n",
    "            pred = self.dropout_2(pred)  # batch x target_len x 2 hdim\n",
    "            pred = self.hidden2out(pred).detach()\n",
    "            x_target = t.cat([x_target, pred.max(2)[1]], 1).detach()\n",
    "\n",
    "            # should you stop ?\n",
    "            count_eos += t.sum((pred.max(2)[1] == EOS_TOKEN).long()).data.cpu().numpy()[0]  # `3` is the EOS token\n",
    "            time += 1\n",
    "        return x_target\n",
    "    \n",
    "    def translate_beam(self, x_source,print_beam_row=-1):\n",
    "        self.eval()       \n",
    "\n",
    "        # EMBEDDING\n",
    "        embedded_x_source = self.source_embeddings(x_source)\n",
    "        if self.embed_dropout:\n",
    "            embedded_x_source = self.dropout_1s(embedded_x_source)\n",
    "\n",
    "        terminate_beam = False\n",
    "        batch_size = x_source.size(0) \n",
    "        src_len = x_source.size(1)\n",
    "        \n",
    "        #RECURRENT\n",
    "        hidden1 = self.init_hidden(None, 'enc1', batch_size)\n",
    "        hidden2 = self.init_hidden(None, 'enc2', batch_size)\n",
    "        enc_out, _ = self.encoder_rnn1(embedded_x_source, hidden1)\n",
    "        enc_out, _ = self.encoder_rnn2(self.dropout_1_enc(embedded_x_source + enc_out), hidden2)  # skip connection + dropout\n",
    "        \n",
    "        hidden1 = []\n",
    "        hidden2 = []\n",
    "        \n",
    "        for i in range(self.beam_size):\n",
    "            hidden1.append(self.init_hidden(enc_out, 'dec', x_source.size(0)))\n",
    "            hidden2.append(self.init_hidden(enc_out, 'dec', x_source.size(0)))\n",
    "        \n",
    "        x_target = SOS_TOKEN * np.ones((x_source.size(0), 1))  # `2` is the SOS token (<s>)\n",
    "        count_eos = 0\n",
    "        time = 0\n",
    "\n",
    "        # INIT SOME STUFF.\n",
    "        self.beam = np.array(x_target)\n",
    "        self.beam_scores = np.zeros((batch_size, 1))\n",
    "       \n",
    "        while not terminate_beam and time < self.max_beam_depth:\n",
    "            collective_children = np.array([])\n",
    "            collective_scores = np.array([])\n",
    "            hidden12 = []\n",
    "\n",
    "            #Happens the first time when you do not have beam candidates.  \n",
    "            if len(self.beam.shape) < 3:\n",
    "                reshaped_beam = self.beam.transpose((1,0))            \n",
    "            else:\n",
    "                reshaped_beam = np.transpose(self.beam,(1,0,2))\n",
    "                \n",
    "            #One for each beam element.\n",
    "            for l in range(reshaped_beam.shape[0]):\n",
    "                hidden12.append(self.init_hidden(enc_out, 'dec', batch_size))                \n",
    "             \n",
    "            for it, elem in enumerate(reshaped_beam):\n",
    "                #PREPROCESSING\n",
    "                \n",
    "                elem = t.from_numpy(elem).long()\n",
    "                x_target = elem.contiguous().view(batch_size, -1)\n",
    "                x_target = variable(x_target, to_float=False, cuda=self.cuda_flag).long()\n",
    "                \n",
    "                #ACTUAL FORWARD\n",
    "                embedded_x_target = self.target_embeddings(x_target)\n",
    "                #it - one for each beam element - They should not share hidden layers.\n",
    "                hidden1[it] = hidden12[it][0][:1, :, :], hidden12[it][1][:1, :, :]\n",
    "                hidden2[it] = hidden12[it][0][1:, :, :], hidden12[it][1][1:, :, :]\n",
    "                dec_out, _ = self.decoder_rnn1(embedded_x_target, hidden1[it])\n",
    "                dec_out, _ = self.decoder_rnn2(self.dropout_1_dec(embedded_x_target + dec_out), hidden2[it])\n",
    "                dec_out = dec_out[:, time:time + 1, :].detach()\n",
    "                \n",
    "                # ATTENTION: just like in the paper\n",
    "                scores = self.linear_attn(F.tanh(\n",
    "                    self.linear_enc(enc_out).unsqueeze(2).expand(batch_size, src_len, 1, self.hidden_dim) +\n",
    "                    self.linear_dec(dec_out).unsqueeze(1).expand(batch_size, src_len, 1, self.hidden_dim)\n",
    "                )).squeeze(3)\n",
    "                attn_dist = F.softmax(scores, dim=1)  # batch x source_len x target_len\n",
    "                context = t.bmm(attn_dist.permute(0, 2, 1), enc_out)  # batch x target_len x hidden_dim\n",
    "\n",
    "                # OUTPUT\n",
    "                # concatenate the output of the decoder and the context and apply nonlinearity\n",
    "                pred = F.tanh(t.cat([dec_out, context], -1))\n",
    "                pred = self.dropout_2(pred)  # batch x target_len x 2 hdim\n",
    "                pred = self.hidden2out(pred).detach()\n",
    "                pred = self.lsm(pred.view(batch_size,-1)).detach()\n",
    "\n",
    "                topk = t.topk(pred, self.beam_size, dim=1)\n",
    "                top_k_indices, top_k_scores = topk[1], topk[0]\n",
    "                top_k_indices = top_k_indices.transpose(0,1)\n",
    "                top_k_scores = top_k_scores.transpose(0,1)\n",
    "                \n",
    "                #import pdb; pdb.set_trace()\n",
    "                \n",
    "                for new_word_batch, new_score_batch in zip(top_k_indices, top_k_scores):\n",
    "                    new_word_batch = new_word_batch.contiguous().view(batch_size,1)\n",
    "                    new_score_batch = new_score_batch.contiguous().view(batch_size,1)\n",
    "                     \n",
    "                    new_child_batch = t.cat([x_target, new_word_batch], 1).detach()\n",
    "\n",
    "                    batch_parent_score = self.beam_scores[:, it].reshape((batch_size, 1))\n",
    "                    batch_acc_score = batch_parent_score + new_score_batch.data.cpu().numpy()\n",
    "\n",
    "                    if len(collective_children) > 0:\n",
    "                        collective_children = np.hstack((collective_children, new_child_batch.data.cpu().numpy()))\n",
    "                        # Add the corresponding beam element's score with the new score and stack it.\n",
    "                        collective_scores = np.hstack((collective_scores, batch_acc_score))\n",
    "                    else:\n",
    "                        collective_children, collective_scores = new_child_batch.data.cpu().numpy(), batch_acc_score\n",
    "\n",
    "\n",
    "            current_beam_length = self.beam.shape[1]            \n",
    "            collective_children = collective_children.reshape((batch_size, current_beam_length * self.beam_size,\n",
    "                                                               int(collective_children.shape[1] /\n",
    "                                                                   current_beam_length / self.beam_size)\n",
    "                                                               ))\n",
    "\n",
    "            if collective_children.shape[1] == self.beam_size:  # Happens the first time.\n",
    "                self.beam = collective_children\n",
    "                self.beam_scores = collective_scores\n",
    "                if print_beam_row > -1:\n",
    "                    for l in range(self.beam_size):\n",
    "                        print([EN.vocab.itos[int(x)] for x in self.beam[print_beam_row,int(l)]])\n",
    "            else:\n",
    "                self.beam = deepcopy(np.zeros((batch_size, self.beam_size, collective_children.shape[2])))\n",
    "                #import pdb; pdb.set_trace()\n",
    "                for i in range(batch_size):\n",
    "                    # Since argsort gives ascending order\n",
    "                    best_scores_indices = np.argsort(-1 * collective_scores[i])[:self.beam_size]\n",
    "                    for key, index in enumerate(best_scores_indices):\n",
    "                        self.beam[i][key][:] = collective_children[i][index]\n",
    "                        self.beam_scores[i][key] = collective_scores[i][index]\n",
    "                if print_beam_row > -1:\n",
    "                    for l in range(self.beam_size):\n",
    "                        print([EN.vocab.itos[int(x)] for x in self.beam[print_beam_row,int(l)]])\n",
    "\n",
    "            terminate_beam = True\n",
    "\n",
    "            for x in self.beam:\n",
    "                for c in x:\n",
    "                    if EOS_TOKEN not in c:\n",
    "                        terminate_beam = False\n",
    "                        break\n",
    "                if not terminate_beam:\n",
    "                    break\n",
    "            \n",
    "            \n",
    "            assert (self.beam.shape == (batch_size, self.beam_size, time + 2))\n",
    "\n",
    "            time += 1\n",
    "            #print(time)\n",
    "        return self.beam\n",
    "\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing LSTMF\n",
      "Initializing LSTMA\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from utils import load_model\n",
    "import os\n",
    "os.chdir('../HW3')\n",
    "#from data_process import generate_kaggle_text\n",
    "\n",
    "beam_size = 100\n",
    "max_beam_depth = 5\n",
    "\n",
    "#from translation_models import LSTMA\n",
    "from const import *\n",
    "with open('LSTMF/2.params.json', 'r') as f:\n",
    "    params_lstmf = json.load(f)\n",
    "with open('LSTMA/4.params.json', 'r') as f:\n",
    "    params_lstma = json.load(f)\n",
    "    \n",
    "params_lstmf['beam_size'] = beam_size\n",
    "params_lstmf['max_beam_depth'] = max_beam_depth\n",
    "\n",
    "params_lstma['beam_size'] = beam_size\n",
    "params_lstma['max_beam_depth'] = max_beam_depth\n",
    "\n",
    "lstmf = LSTMF(params_lstmf).cuda()\n",
    "lstma = LSTMA(params_lstma).cuda()\n",
    "\n",
    "load_model(lstma, 'LSTMA/4.pytorch', cuda=True)\n",
    "load_model(lstmf, 'LSTMF/2.pytorch', cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_iter.batch_size = 64\n",
    "for batch in val_iter:\n",
    "    pred_beam = lstma.translate_beam(batch.src.transpose(0,1).cuda(),print_beam_row=6) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstmf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e7005d42d987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpred_beam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate_beam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprint_beam_row\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lstmf' is not defined"
     ]
    }
   ],
   "source": [
    "val_iter.batch_size = 64\n",
    "for batch in val_iter:\n",
    "    pred_beam = lstmf.translate_beam(batch.src.transpose(0,1).cuda(),print_beam_row=6) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escape(l):\n",
    "    return l.replace(\"\\\"\", \"<quote>\").replace(\",\", \"<comma>\")\n",
    "\n",
    "def generate_kaggle_text( trained_model, DE, EN, batch_size, beam_size, total_sentences, num_words =3, \n",
    "                         expt_name = \"LSTM_Attention\", debug = False, print_on_screen = False,start_from = 0):\n",
    "    batch_count = 0\n",
    "    if start_from == 0:\n",
    "        top_predictions = np.ones((total_sentences,beam_size,num_words))*-1\n",
    "    else:\n",
    "        top_predictions = np.load('kaggle_predictions.npy')\n",
    "\n",
    "    it = 0\n",
    "    for line in open('source_test.txt'):\n",
    "        if batch_count >= start_from:\n",
    "            words = line.split()  \n",
    "            line_int = np.array([DE.vocab.stoi[w] for w in words])         \n",
    "\n",
    "            line_int_tensor = t.from_numpy(line_int)\n",
    "            line_int_tensor = Variable(line_int_tensor.view(1,-1))      \n",
    "\n",
    "            pred_beam = trained_model.translate_beam(line_int_tensor.cuda()) \n",
    "\n",
    "            for i in range(batch_size):\n",
    "                for j in range(beam_size) :                \n",
    "                    top_predictions[batch_count*batch_size+i,j] = pred_beam[i,j,1:num_words+1]\n",
    "                    np.save(\"kaggle_predictions\",top_predictions)\n",
    "\n",
    "        batch_count += 1\n",
    "\n",
    "        if debug:\n",
    "            if batch_count == 2:\n",
    "                break\n",
    "        print(batch_count, \" of 800 over\") \n",
    "    \n",
    "    np.save(\"kaggle_predictions\",top_predictions)        \n",
    "\n",
    "    if not print_on_screen:        \n",
    "        with open(expt_name + \".txt\", \"w\") as fout:\n",
    "            print(\"id,word\", file = fout)\n",
    "            for i in range(total_sentences):\n",
    "                print(str(i+1)+\",\",end=\"\",file = fout)\n",
    "                for j in range(beam_size):\n",
    "                    print(\"|\".join([escape(EN.vocab.itos[int(x)]) for x in top_predictions[i][j]]), \" \", end  = \"\",file = fout)\n",
    "                print(\"\",file = fout)\n",
    "    else:\n",
    "        print(\"id,word\")\n",
    "        for i in range(total_sentences):\n",
    "            print(str(i+1)+\",\",end=\"\")\n",
    "            for j in range(beam_size):\n",
    "                print(\"|\".join([escape(EN.vocab.itos[int(x)]) for x in top_predictions[i][j]]), \" \", end  = \"\")\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  of 800 over\n",
      "2  of 800 over\n",
      "3  of 800 over\n",
      "4  of 800 over\n",
      "5  of 800 over\n",
      "6  of 800 over\n",
      "7  of 800 over\n",
      "8  of 800 over\n",
      "9  of 800 over\n",
      "10  of 800 over\n",
      "11  of 800 over\n",
      "12  of 800 over\n",
      "13  of 800 over\n",
      "14  of 800 over\n",
      "15  of 800 over\n",
      "16  of 800 over\n",
      "17  of 800 over\n",
      "18  of 800 over\n",
      "19  of 800 over\n",
      "20  of 800 over\n",
      "21  of 800 over\n",
      "22  of 800 over\n",
      "23  of 800 over\n",
      "24  of 800 over\n",
      "25  of 800 over\n",
      "26  of 800 over\n",
      "27  of 800 over\n",
      "28  of 800 over\n",
      "29  of 800 over\n",
      "30  of 800 over\n",
      "31  of 800 over\n",
      "32  of 800 over\n",
      "33  of 800 over\n",
      "34  of 800 over\n",
      "35  of 800 over\n",
      "36  of 800 over\n",
      "37  of 800 over\n",
      "38  of 800 over\n",
      "39  of 800 over\n",
      "40  of 800 over\n",
      "41  of 800 over\n",
      "42  of 800 over\n",
      "43  of 800 over\n",
      "44  of 800 over\n",
      "45  of 800 over\n",
      "46  of 800 over\n",
      "47  of 800 over\n",
      "48  of 800 over\n",
      "49  of 800 over\n",
      "50  of 800 over\n",
      "51  of 800 over\n",
      "52  of 800 over\n",
      "53  of 800 over\n",
      "54  of 800 over\n",
      "55  of 800 over\n",
      "56  of 800 over\n",
      "57  of 800 over\n",
      "58  of 800 over\n",
      "59  of 800 over\n",
      "60  of 800 over\n",
      "61  of 800 over\n",
      "62  of 800 over\n",
      "63  of 800 over\n",
      "64  of 800 over\n",
      "65  of 800 over\n",
      "66  of 800 over\n",
      "67  of 800 over\n",
      "68  of 800 over\n",
      "69  of 800 over\n",
      "70  of 800 over\n",
      "71  of 800 over\n",
      "72  of 800 over\n",
      "73  of 800 over\n",
      "74  of 800 over\n",
      "75  of 800 over\n",
      "76  of 800 over\n",
      "77  of 800 over\n",
      "78  of 800 over\n",
      "79  of 800 over\n",
      "80  of 800 over\n",
      "81  of 800 over\n",
      "82  of 800 over\n",
      "83  of 800 over\n",
      "84  of 800 over\n",
      "85  of 800 over\n",
      "86  of 800 over\n",
      "87  of 800 over\n",
      "88  of 800 over\n",
      "89  of 800 over\n",
      "90  of 800 over\n",
      "91  of 800 over\n",
      "92  of 800 over\n",
      "93  of 800 over\n",
      "94  of 800 over\n",
      "95  of 800 over\n",
      "96  of 800 over\n",
      "97  of 800 over\n",
      "98  of 800 over\n",
      "99  of 800 over\n",
      "100  of 800 over\n",
      "101  of 800 over\n",
      "102  of 800 over\n",
      "103  of 800 over\n",
      "104  of 800 over\n",
      "105  of 800 over\n",
      "106  of 800 over\n",
      "107  of 800 over\n",
      "108  of 800 over\n",
      "109  of 800 over\n",
      "110  of 800 over\n",
      "111  of 800 over\n",
      "112  of 800 over\n",
      "113  of 800 over\n",
      "114  of 800 over\n",
      "115  of 800 over\n",
      "116  of 800 over\n",
      "117  of 800 over\n",
      "118  of 800 over\n",
      "119  of 800 over\n",
      "120  of 800 over\n",
      "121  of 800 over\n",
      "122  of 800 over\n",
      "123  of 800 over\n",
      "124  of 800 over\n",
      "125  of 800 over\n",
      "126  of 800 over\n",
      "127  of 800 over\n",
      "128  of 800 over\n",
      "129  of 800 over\n",
      "130  of 800 over\n",
      "131  of 800 over\n",
      "132  of 800 over\n",
      "133  of 800 over\n",
      "134  of 800 over\n",
      "135  of 800 over\n",
      "136  of 800 over\n",
      "137  of 800 over\n",
      "138  of 800 over\n",
      "139  of 800 over\n",
      "140  of 800 over\n",
      "141  of 800 over\n",
      "142  of 800 over\n",
      "143  of 800 over\n",
      "144  of 800 over\n",
      "145  of 800 over\n",
      "146  of 800 over\n",
      "147  of 800 over\n",
      "148  of 800 over\n",
      "149  of 800 over\n",
      "150  of 800 over\n",
      "151  of 800 over\n",
      "152  of 800 over\n",
      "153  of 800 over\n",
      "154  of 800 over\n",
      "155  of 800 over\n",
      "156  of 800 over\n",
      "157  of 800 over\n",
      "158  of 800 over\n",
      "159  of 800 over\n",
      "160  of 800 over\n",
      "161  of 800 over\n",
      "162  of 800 over\n",
      "163  of 800 over\n",
      "164  of 800 over\n",
      "165  of 800 over\n",
      "166  of 800 over\n",
      "167  of 800 over\n",
      "168  of 800 over\n",
      "169  of 800 over\n",
      "170  of 800 over\n",
      "171  of 800 over\n",
      "172  of 800 over\n",
      "173  of 800 over\n",
      "174  of 800 over\n",
      "175  of 800 over\n",
      "176  of 800 over\n",
      "177  of 800 over\n",
      "178  of 800 over\n",
      "179  of 800 over\n",
      "180  of 800 over\n",
      "181  of 800 over\n",
      "182  of 800 over\n",
      "183  of 800 over\n",
      "184  of 800 over\n",
      "185  of 800 over\n",
      "186  of 800 over\n",
      "187  of 800 over\n",
      "188  of 800 over\n",
      "189  of 800 over\n",
      "190  of 800 over\n",
      "191  of 800 over\n",
      "192  of 800 over\n",
      "193  of 800 over\n",
      "194  of 800 over\n",
      "195  of 800 over\n",
      "196  of 800 over\n",
      "197  of 800 over\n",
      "198  of 800 over\n",
      "199  of 800 over\n",
      "200  of 800 over\n",
      "201  of 800 over\n",
      "202  of 800 over\n",
      "203  of 800 over\n",
      "204  of 800 over\n",
      "205  of 800 over\n",
      "206  of 800 over\n",
      "207  of 800 over\n",
      "208  of 800 over\n",
      "209  of 800 over\n",
      "210  of 800 over\n",
      "211  of 800 over\n",
      "212  of 800 over\n",
      "213  of 800 over\n",
      "214  of 800 over\n",
      "215  of 800 over\n",
      "216  of 800 over\n",
      "217  of 800 over\n",
      "218  of 800 over\n",
      "219  of 800 over\n",
      "220  of 800 over\n",
      "221  of 800 over\n",
      "222  of 800 over\n",
      "223  of 800 over\n",
      "224  of 800 over\n",
      "225  of 800 over\n",
      "226  of 800 over\n",
      "227  of 800 over\n",
      "228  of 800 over\n",
      "229  of 800 over\n",
      "230  of 800 over\n",
      "231  of 800 over\n",
      "232  of 800 over\n",
      "233  of 800 over\n",
      "234  of 800 over\n",
      "235  of 800 over\n",
      "236  of 800 over\n",
      "237  of 800 over\n",
      "238  of 800 over\n",
      "239  of 800 over\n",
      "240  of 800 over\n",
      "241  of 800 over\n",
      "242  of 800 over\n",
      "243  of 800 over\n",
      "244  of 800 over\n",
      "245  of 800 over\n",
      "246  of 800 over\n",
      "247  of 800 over\n",
      "248  of 800 over\n",
      "249  of 800 over\n",
      "250  of 800 over\n",
      "251  of 800 over\n",
      "252  of 800 over\n",
      "253  of 800 over\n",
      "254  of 800 over\n",
      "255  of 800 over\n",
      "256  of 800 over\n",
      "257  of 800 over\n",
      "258  of 800 over\n",
      "259  of 800 over\n",
      "260  of 800 over\n",
      "261  of 800 over\n",
      "262  of 800 over\n",
      "263  of 800 over\n",
      "264  of 800 over\n",
      "265  of 800 over\n",
      "266  of 800 over\n",
      "267  of 800 over\n",
      "268  of 800 over\n",
      "269  of 800 over\n",
      "270  of 800 over\n",
      "271  of 800 over\n",
      "272  of 800 over\n",
      "273  of 800 over\n",
      "274  of 800 over\n",
      "275  of 800 over\n",
      "276  of 800 over\n",
      "277  of 800 over\n",
      "278  of 800 over\n",
      "279  of 800 over\n",
      "280  of 800 over\n",
      "281  of 800 over\n",
      "282  of 800 over\n",
      "283  of 800 over\n",
      "284  of 800 over\n",
      "285  of 800 over\n",
      "286  of 800 over\n",
      "287  of 800 over\n",
      "288  of 800 over\n",
      "289  of 800 over\n",
      "290  of 800 over\n",
      "291  of 800 over\n",
      "292  of 800 over\n",
      "293  of 800 over\n",
      "294  of 800 over\n",
      "295  of 800 over\n",
      "296  of 800 over\n",
      "297  of 800 over\n",
      "298  of 800 over\n",
      "299  of 800 over\n",
      "300  of 800 over\n",
      "301  of 800 over\n",
      "302  of 800 over\n",
      "303  of 800 over\n",
      "304  of 800 over\n",
      "305  of 800 over\n",
      "306  of 800 over\n",
      "307  of 800 over\n",
      "308  of 800 over\n",
      "309  of 800 over\n",
      "310  of 800 over\n",
      "311  of 800 over\n",
      "312  of 800 over\n",
      "313  of 800 over\n",
      "314  of 800 over\n",
      "315  of 800 over\n",
      "316  of 800 over\n",
      "317  of 800 over\n",
      "318  of 800 over\n",
      "319  of 800 over\n",
      "320  of 800 over\n",
      "321  of 800 over\n",
      "322  of 800 over\n",
      "323  of 800 over\n",
      "324  of 800 over\n",
      "325  of 800 over\n",
      "326  of 800 over\n",
      "327  of 800 over\n",
      "328  of 800 over\n",
      "329  of 800 over\n",
      "330  of 800 over\n",
      "331  of 800 over\n",
      "332  of 800 over\n",
      "333  of 800 over\n",
      "334  of 800 over\n",
      "335  of 800 over\n",
      "336  of 800 over\n",
      "337  of 800 over\n",
      "338  of 800 over\n",
      "339  of 800 over\n",
      "340  of 800 over\n",
      "341  of 800 over\n",
      "342  of 800 over\n",
      "343  of 800 over\n",
      "344  of 800 over\n",
      "345  of 800 over\n",
      "346  of 800 over\n",
      "347  of 800 over\n",
      "348  of 800 over\n",
      "349  of 800 over\n",
      "350  of 800 over\n",
      "351  of 800 over\n",
      "352  of 800 over\n",
      "353  of 800 over\n",
      "354  of 800 over\n",
      "355  of 800 over\n",
      "356  of 800 over\n",
      "357  of 800 over\n",
      "358  of 800 over\n",
      "359  of 800 over\n",
      "360  of 800 over\n",
      "361  of 800 over\n",
      "362  of 800 over\n",
      "363  of 800 over\n",
      "364  of 800 over\n",
      "365  of 800 over\n",
      "366  of 800 over\n",
      "367  of 800 over\n",
      "368  of 800 over\n",
      "369  of 800 over\n",
      "370  of 800 over\n",
      "371  of 800 over\n",
      "372  of 800 over\n",
      "373  of 800 over\n",
      "374  of 800 over\n",
      "375  of 800 over\n",
      "376  of 800 over\n",
      "377  of 800 over\n",
      "378  of 800 over\n",
      "379  of 800 over\n",
      "380  of 800 over\n",
      "381  of 800 over\n",
      "382  of 800 over\n",
      "383  of 800 over\n",
      "384  of 800 over\n",
      "385  of 800 over\n",
      "386  of 800 over\n",
      "387  of 800 over\n",
      "388  of 800 over\n",
      "389  of 800 over\n",
      "390  of 800 over\n",
      "391  of 800 over\n",
      "392  of 800 over\n",
      "393  of 800 over\n",
      "394  of 800 over\n",
      "395  of 800 over\n",
      "396  of 800 over\n",
      "397  of 800 over\n",
      "398  of 800 over\n",
      "399  of 800 over\n",
      "400  of 800 over\n",
      "401  of 800 over\n",
      "402  of 800 over\n",
      "403  of 800 over\n",
      "404  of 800 over\n",
      "405  of 800 over\n",
      "406  of 800 over\n",
      "407  of 800 over\n",
      "408  of 800 over\n",
      "409  of 800 over\n",
      "410  of 800 over\n",
      "411  of 800 over\n",
      "412  of 800 over\n",
      "413  of 800 over\n",
      "414  of 800 over\n",
      "415  of 800 over\n",
      "416  of 800 over\n",
      "417  of 800 over\n",
      "418  of 800 over\n",
      "419  of 800 over\n",
      "420  of 800 over\n",
      "421  of 800 over\n",
      "422  of 800 over\n",
      "423  of 800 over\n",
      "424  of 800 over\n",
      "425  of 800 over\n",
      "426  of 800 over\n",
      "427  of 800 over\n",
      "428  of 800 over\n",
      "429  of 800 over\n",
      "430  of 800 over\n",
      "431  of 800 over\n",
      "432  of 800 over\n",
      "433  of 800 over\n",
      "434  of 800 over\n",
      "435  of 800 over\n",
      "436  of 800 over\n",
      "437  of 800 over\n",
      "438  of 800 over\n",
      "439  of 800 over\n",
      "440  of 800 over\n",
      "441  of 800 over\n",
      "442  of 800 over\n",
      "443  of 800 over\n",
      "444  of 800 over\n",
      "445  of 800 over\n",
      "446  of 800 over\n",
      "447  of 800 over\n",
      "448  of 800 over\n",
      "449  of 800 over\n",
      "450  of 800 over\n",
      "451  of 800 over\n",
      "452  of 800 over\n",
      "453  of 800 over\n",
      "454  of 800 over\n",
      "455  of 800 over\n",
      "456  of 800 over\n",
      "457  of 800 over\n",
      "458  of 800 over\n",
      "459  of 800 over\n",
      "460  of 800 over\n",
      "461  of 800 over\n",
      "462  of 800 over\n",
      "463  of 800 over\n",
      "464  of 800 over\n",
      "465  of 800 over\n",
      "466  of 800 over\n",
      "467  of 800 over\n",
      "468  of 800 over\n",
      "469  of 800 over\n",
      "470  of 800 over\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:280: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471  of 800 over\n",
      "472  of 800 over\n",
      "473  of 800 over\n",
      "474  of 800 over\n",
      "475  of 800 over\n",
      "476  of 800 over\n",
      "477  of 800 over\n",
      "478  of 800 over\n",
      "479  of 800 over\n",
      "480  of 800 over\n",
      "481  of 800 over\n",
      "482  of 800 over\n",
      "483  of 800 over\n",
      "484  of 800 over\n",
      "485  of 800 over\n",
      "486  of 800 over\n",
      "487  of 800 over\n",
      "488  of 800 over\n",
      "489  of 800 over\n",
      "490  of 800 over\n",
      "491  of 800 over\n",
      "492  of 800 over\n",
      "493  of 800 over\n",
      "494  of 800 over\n",
      "495  of 800 over\n",
      "496  of 800 over\n",
      "497  of 800 over\n",
      "498  of 800 over\n",
      "499  of 800 over\n",
      "500  of 800 over\n",
      "501  of 800 over\n",
      "502  of 800 over\n",
      "503  of 800 over\n",
      "504  of 800 over\n",
      "505  of 800 over\n",
      "506  of 800 over\n",
      "507  of 800 over\n",
      "508  of 800 over\n",
      "509  of 800 over\n",
      "510  of 800 over\n",
      "511  of 800 over\n",
      "512  of 800 over\n",
      "513  of 800 over\n",
      "514  of 800 over\n",
      "515  of 800 over\n",
      "516  of 800 over\n",
      "517  of 800 over\n",
      "518  of 800 over\n",
      "519  of 800 over\n",
      "520  of 800 over\n",
      "521  of 800 over\n",
      "522  of 800 over\n",
      "523  of 800 over\n",
      "524  of 800 over\n",
      "525  of 800 over\n",
      "526  of 800 over\n",
      "527  of 800 over\n",
      "528  of 800 over\n",
      "529  of 800 over\n",
      "530  of 800 over\n",
      "531  of 800 over\n",
      "532  of 800 over\n",
      "533  of 800 over\n",
      "534  of 800 over\n",
      "535  of 800 over\n",
      "536  of 800 over\n",
      "537  of 800 over\n",
      "538  of 800 over\n",
      "539  of 800 over\n",
      "540  of 800 over\n",
      "541  of 800 over\n",
      "542  of 800 over\n",
      "543  of 800 over\n",
      "544  of 800 over\n",
      "545  of 800 over\n",
      "546  of 800 over\n",
      "547  of 800 over\n",
      "548  of 800 over\n",
      "549  of 800 over\n",
      "550  of 800 over\n",
      "551  of 800 over\n",
      "552  of 800 over\n",
      "553  of 800 over\n",
      "554  of 800 over\n",
      "555  of 800 over\n",
      "556  of 800 over\n",
      "557  of 800 over\n",
      "558  of 800 over\n",
      "559  of 800 over\n",
      "560  of 800 over\n",
      "561  of 800 over\n",
      "562  of 800 over\n",
      "563  of 800 over\n",
      "564  of 800 over\n",
      "565  of 800 over\n",
      "566  of 800 over\n",
      "567  of 800 over\n",
      "568  of 800 over\n",
      "569  of 800 over\n",
      "570  of 800 over\n",
      "571  of 800 over\n",
      "572  of 800 over\n",
      "573  of 800 over\n",
      "574  of 800 over\n",
      "575  of 800 over\n",
      "576  of 800 over\n",
      "577  of 800 over\n",
      "578  of 800 over\n",
      "579  of 800 over\n",
      "580  of 800 over\n",
      "581  of 800 over\n",
      "582  of 800 over\n",
      "583  of 800 over\n",
      "584  of 800 over\n",
      "585  of 800 over\n",
      "586  of 800 over\n",
      "587  of 800 over\n",
      "588  of 800 over\n",
      "589  of 800 over\n",
      "590  of 800 over\n",
      "591  of 800 over\n",
      "592  of 800 over\n",
      "593  of 800 over\n",
      "594  of 800 over\n",
      "595  of 800 over\n",
      "596  of 800 over\n",
      "597  of 800 over\n",
      "598  of 800 over\n",
      "599  of 800 over\n",
      "600  of 800 over\n",
      "601  of 800 over\n",
      "602  of 800 over\n",
      "603  of 800 over\n",
      "604  of 800 over\n",
      "605  of 800 over\n",
      "606  of 800 over\n",
      "607  of 800 over\n",
      "608  of 800 over\n",
      "609  of 800 over\n",
      "610  of 800 over\n",
      "611  of 800 over\n",
      "612  of 800 over\n",
      "613  of 800 over\n",
      "614  of 800 over\n",
      "615  of 800 over\n",
      "616  of 800 over\n",
      "617  of 800 over\n",
      "618  of 800 over\n",
      "619  of 800 over\n",
      "620  of 800 over\n",
      "621  of 800 over\n",
      "622  of 800 over\n",
      "623  of 800 over\n",
      "624  of 800 over\n",
      "625  of 800 over\n",
      "626  of 800 over\n",
      "627  of 800 over\n",
      "628  of 800 over\n",
      "629  of 800 over\n",
      "630  of 800 over\n",
      "631  of 800 over\n",
      "632  of 800 over\n",
      "633  of 800 over\n",
      "634  of 800 over\n",
      "635  of 800 over\n",
      "636  of 800 over\n",
      "637  of 800 over\n",
      "638  of 800 over\n",
      "639  of 800 over\n",
      "640  of 800 over\n",
      "641  of 800 over\n",
      "642  of 800 over\n",
      "643  of 800 over\n",
      "644  of 800 over\n",
      "645  of 800 over\n",
      "646  of 800 over\n",
      "647  of 800 over\n",
      "648  of 800 over\n",
      "649  of 800 over\n",
      "650  of 800 over\n",
      "651  of 800 over\n",
      "652  of 800 over\n",
      "653  of 800 over\n",
      "654  of 800 over\n",
      "655  of 800 over\n",
      "656  of 800 over\n",
      "657  of 800 over\n",
      "658  of 800 over\n",
      "659  of 800 over\n",
      "660  of 800 over\n",
      "661  of 800 over\n",
      "662  of 800 over\n",
      "663  of 800 over\n",
      "664  of 800 over\n",
      "665  of 800 over\n",
      "666  of 800 over\n",
      "667  of 800 over\n",
      "668  of 800 over\n",
      "669  of 800 over\n",
      "670  of 800 over\n",
      "671  of 800 over\n",
      "672  of 800 over\n",
      "673  of 800 over\n",
      "674  of 800 over\n",
      "675  of 800 over\n",
      "676  of 800 over\n",
      "677  of 800 over\n",
      "678  of 800 over\n",
      "679  of 800 over\n",
      "680  of 800 over\n",
      "681  of 800 over\n",
      "682  of 800 over\n",
      "683  of 800 over\n",
      "684  of 800 over\n",
      "685  of 800 over\n",
      "686  of 800 over\n",
      "687  of 800 over\n",
      "688  of 800 over\n",
      "689  of 800 over\n",
      "690  of 800 over\n",
      "691  of 800 over\n",
      "692  of 800 over\n",
      "693  of 800 over\n",
      "694  of 800 over\n",
      "695  of 800 over\n",
      "696  of 800 over\n",
      "697  of 800 over\n",
      "698  of 800 over\n",
      "699  of 800 over\n",
      "700  of 800 over\n",
      "701  of 800 over\n",
      "702  of 800 over\n",
      "703  of 800 over\n",
      "704  of 800 over\n",
      "705  of 800 over\n",
      "706  of 800 over\n",
      "707  of 800 over\n",
      "708  of 800 over\n",
      "709  of 800 over\n",
      "710  of 800 over\n",
      "711  of 800 over\n",
      "712  of 800 over\n",
      "713  of 800 over\n",
      "714  of 800 over\n",
      "715  of 800 over\n",
      "716  of 800 over\n",
      "717  of 800 over\n",
      "718  of 800 over\n",
      "719  of 800 over\n",
      "720  of 800 over\n",
      "721  of 800 over\n",
      "722  of 800 over\n",
      "723  of 800 over\n",
      "724  of 800 over\n",
      "725  of 800 over\n",
      "726  of 800 over\n",
      "727  of 800 over\n",
      "728  of 800 over\n",
      "729  of 800 over\n",
      "730  of 800 over\n",
      "731  of 800 over\n",
      "732  of 800 over\n",
      "733  of 800 over\n",
      "734  of 800 over\n",
      "735  of 800 over\n",
      "736  of 800 over\n",
      "737  of 800 over\n",
      "738  of 800 over\n",
      "739  of 800 over\n",
      "740  of 800 over\n",
      "741  of 800 over\n",
      "742  of 800 over\n",
      "743  of 800 over\n",
      "744  of 800 over\n",
      "745  of 800 over\n",
      "746  of 800 over\n",
      "747  of 800 over\n",
      "748  of 800 over\n",
      "749  of 800 over\n",
      "750  of 800 over\n",
      "751  of 800 over\n",
      "752  of 800 over\n",
      "753  of 800 over\n",
      "754  of 800 over\n",
      "755  of 800 over\n",
      "756  of 800 over\n",
      "757  of 800 over\n",
      "758  of 800 over\n",
      "759  of 800 over\n",
      "760  of 800 over\n",
      "761  of 800 over\n",
      "762  of 800 over\n",
      "763  of 800 over\n",
      "764  of 800 over\n",
      "765  of 800 over\n",
      "766  of 800 over\n",
      "767  of 800 over\n",
      "768  of 800 over\n",
      "769  of 800 over\n",
      "770  of 800 over\n",
      "771  of 800 over\n",
      "772  of 800 over\n",
      "773  of 800 over\n",
      "774  of 800 over\n",
      "775  of 800 over\n",
      "776  of 800 over\n",
      "777  of 800 over\n",
      "778  of 800 over\n",
      "779  of 800 over\n",
      "780  of 800 over\n",
      "781  of 800 over\n",
      "782  of 800 over\n",
      "783  of 800 over\n",
      "784  of 800 over\n",
      "785  of 800 over\n",
      "786  of 800 over\n",
      "787  of 800 over\n",
      "788  of 800 over\n",
      "789  of 800 over\n",
      "790  of 800 over\n",
      "791  of 800 over\n",
      "792  of 800 over\n",
      "793  of 800 over\n",
      "794  of 800 over\n",
      "795  of 800 over\n",
      "796  of 800 over\n",
      "797  of 800 over\n",
      "798  of 800 over\n",
      "799  of 800 over\n",
      "800  of 800 over\n"
     ]
    }
   ],
   "source": [
    "batch_size,beam_size,tot = 1,100,800\n",
    "lstma.batch_size = batch_size\n",
    "generate_kaggle_text(lstmf,DE,EN,batch_size,beam_size,tot,debug=False,print_on_screen = False, expt_name='LSTMF',start_from = 470)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_iter.batch_size = 64\n",
    "for batch in val_iter:\n",
    "    break\n",
    "pred = lstma.translate(batch.src.transpose(0,1).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  TEST BEAM PREDICTION - remember beam is of dimension - batch size * beam size . so pred_beam[a][b] will give ath element \n",
    "\n",
    "in the batch and its bth beam value. b= 0 will be the most likely option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_elem = 13\n",
    "\n",
    "print(\"beam's best prediction(Change 0 to other elem for other predicitons) : \")\n",
    "print([EN.vocab.itos[int(x)] for x in pred_beam[batch_elem][0]])\n",
    "print(\"Greedy prediction : \")\n",
    "print([EN.vocab.itos[int(x)] for x in pred[batch_elem].data.cpu().numpy()])\n",
    "print(\"actual text\")\n",
    "print([EN.vocab.itos[x] for x in batch.trg.transpose(0,1)[batch_elem].data.numpy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lines = sum(1 for line in open('source_test.txt'))\n",
    "print(\"Num lines in text file : \", num_lines)\n",
    "print(\"Test dataset size : \", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits((train, val,test), batch_size=BATCH_SIZE, device=-1, shuffle = False, repeat=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open('source_test.txt'):\n",
    "    print(line)\n",
    "    break\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "a = np.load(\"kaggle_predictions.npy\")\n",
    "print(a[471][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
