{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "os.chdir('../HW3')  # so that there is not any import bug in case HW2 is not already the working directory\n",
    "from utils import *\n",
    "from const import *\n",
    "import argparse\n",
    "import torch as t\n",
    "from process_params import check_args, get_params\n",
    "from const import *\n",
    "from data_process import generate_iterators, generate_text\n",
    "from utils import *\n",
    "t.manual_seed(1)\n",
    "\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "from utils import variable\n",
    "from const import *\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import spacy\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import pickle\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_TOKEN=2\n",
    "EOS_TOKEN=3\n",
    "class LSTM(t.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of `Sequence to Sequence Learning with Neural Networks`\n",
    "    https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "\n",
    "    NOTE THAT ITS INPUT SHOULD HAVE THE BATCH SIZE FIRST !!!!!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, source_embeddings=None, target_embeddings=None):\n",
    "        super(LSTM, self).__init__()\n",
    "        print(\"Initializing LSTM\")\n",
    "        self.cuda_flag = params.get('cuda', CUDA_DEFAULT)\n",
    "        self.model_str = 'LSTM'\n",
    "        self.params = params\n",
    "\n",
    "        # Initialize hyperparams.\n",
    "        self.hidden_dim = params.get('hidden_dim', 100)\n",
    "        self.batch_size = params.get('batch_size', 32)\n",
    "        try:\n",
    "            # if you provide pre-trained embeddings for target/source, they should have the same embedding dim\n",
    "            self.source_vocab_size = params.get('source_vocab_size')\n",
    "            self.target_vocab_size = params.get('target_vocab_size')\n",
    "            assert source_embeddings.size(1) == target_embeddings.size(1)\n",
    "            self.embedding_dim = source_embeddings.size(1)\n",
    "        except:\n",
    "            # if you dont provide a pre-trained embedding, you have to provide these\n",
    "            self.source_vocab_size = params.get('source_vocab_size')\n",
    "            self.target_vocab_size = params.get('target_vocab_size')\n",
    "            self.embedding_dim = params.get('embedding_dim')\n",
    "            assert self.embedding_dim is not None and self.source_vocab_size is not None and self.target_vocab_size is not None\n",
    "        self.output_size = self.target_vocab_size\n",
    "        self.num_layers = params.get('num_layers', 1)\n",
    "        self.dropout = params.get('dropout', 0.5)\n",
    "        self.embed_dropout = params.get('embed_dropout')\n",
    "        self.train_embedding = params.get('train_embedding', False)\n",
    "\n",
    "        # Initialize embeddings. Static embeddings for now.\n",
    "        self.source_embeddings = t.nn.Embedding(self.source_vocab_size, self.embedding_dim)\n",
    "        self.target_embeddings = t.nn.Embedding(self.target_vocab_size, self.embedding_dim)\n",
    "        if source_embeddings is not None:\n",
    "            self.source_embeddings.weight = t.nn.Parameter(source_embeddings, requires_grad=self.train_embedding)\n",
    "        if target_embeddings is not None:\n",
    "            self.target_embeddings.weight = t.nn.Parameter(target_embeddings, requires_grad=self.train_embedding)\n",
    "\n",
    "        # Initialize network modules.\n",
    "        self.encoder_rnn = t.nn.LSTM(self.embedding_dim, self.hidden_dim, dropout=self.dropout, num_layers=self.num_layers, batch_first=True)\n",
    "        self.decoder_rnn = t.nn.LSTM(self.embedding_dim + self.hidden_dim, self.hidden_dim, dropout=self.dropout, num_layers=self.num_layers, batch_first=True)\n",
    "        self.hidden2out = t.nn.Linear(self.hidden_dim, self.output_size)\n",
    "        self.hidden_enc = self.init_hidden()\n",
    "        self.hidden_dec = self.init_hidden()\n",
    "        if self.embed_dropout:\n",
    "            self.dropout_1s = t.nn.Dropout(self.dropout)\n",
    "            self.dropout_1t = t.nn.Dropout(self.dropout)\n",
    "        self.dropout_2 = t.nn.Dropout(self.dropout)\n",
    "        self.lsm = nn.LogSoftmax()\n",
    "        \n",
    "        # Beam Search related.\n",
    "        self.beam = np.array([]) \n",
    "        self.beam_scores = np.array([])\n",
    "        self.beam_size = params.get('beam_size',100)\n",
    "                \n",
    "    def init_hidden(self, batch_size=None):\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim). The helper function\n",
    "        # will return torch variable.\n",
    "        bs = self.batch_size if batch_size is None else batch_size\n",
    "        return tuple((\n",
    "            variable(np.zeros((self.num_layers, bs, self.hidden_dim)), cuda=self.cuda_flag),\n",
    "            variable(np.zeros((self.num_layers, bs, self.hidden_dim)), cuda=self.cuda_flag)\n",
    "        ))\n",
    "\n",
    "    def forward(self, x_source, x_target):\n",
    "        \"\"\"\n",
    "        :param x_source: the source sentence\n",
    "        :param x_target: the target (translated) sentence\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # EMBEDDING\n",
    "        xx_source = self.reverse_source(x_source)\n",
    "        embedded_x_source = self.source_embeddings(xx_source)\n",
    "        embedded_x_target = self.source_embeddings(x_target[:, :-1])\n",
    "        if self.embed_dropout:\n",
    "            embedded_x_source = self.dropout_1s(embedded_x_source)\n",
    "            embedded_x_target = self.dropout_1t(embedded_x_target)\n",
    "\n",
    "        # ENCODING SOURCE SENTENCE INTO FIXED LENGTH VECTOR\n",
    "        _, self.hidden_enc = self.encoder_rnn(embedded_x_source, self.hidden_enc)\n",
    "\n",
    "        # DECODING\n",
    "        embedded_x_target = self.append_hidden_to_target(embedded_x_target)\n",
    "        rnn_out, self.hidden_dec = self.decoder_rnn(embedded_x_target, self.hidden_dec)\n",
    "        rnn_out = self.dropout_2(rnn_out)\n",
    "\n",
    "        # OUTPUT\n",
    "        out_linear = self.hidden2out(rnn_out)\n",
    "        return out_linear\n",
    "    \n",
    "    def translate(self, x_source):\n",
    "        # INITIALIZE\n",
    "        self.eval()\n",
    "    \n",
    "        self.hidden_enc = self.init_hidden()\n",
    "        self.hidden_dec = self.init_hidden()\n",
    "        hidden = self.hidden_dec\n",
    "    \n",
    "        count_eos = 0\n",
    "        time = 0\n",
    "    \n",
    "        x_target = (SOS_TOKEN * t.ones(x_source.size(0), 1)).long()  # `2` is the SOS token (<s>)\n",
    "        x_target = variable(x_target, to_float=False, cuda=self.cuda_flag)\n",
    "    \n",
    "        # EMBEDDING\n",
    "        xx_source = self.reverse_source(x_source)\n",
    "        embedded_x_source = self.source_embeddings(xx_source)\n",
    "        if self.embed_dropout:\n",
    "            embedded_x_source = self.dropout_1s(embedded_x_source)\n",
    "    \n",
    "        # ENCODING SOURCE SENTENCE INTO FIXED LENGTH VECTOR\n",
    "        _, self.hidden_enc = self.encoder_rnn(embedded_x_source, self.hidden_enc)\n",
    "    \n",
    "        while count_eos < x_source.size(0):\n",
    "            embedded_x_target = self.target_embeddings(x_target)\n",
    "            embedded_x_target = self.append_hidden_to_target(embedded_x_target)\n",
    "            dec_out, hidden = self.decoder_rnn(embedded_x_target, hidden)\n",
    "            hidden = hidden[0].detach(), hidden[1].detach()\n",
    "            dec_out = dec_out[:, time:time + 1, :].detach()\n",
    "            dec_out = self.dropout_2(dec_out)\n",
    "    \n",
    "            # OUTPUT\n",
    "            pred = self.hidden2out(dec_out).detach()\n",
    "            # concatenate the output of the decoder and the context and apply nonlinearity\n",
    "            x_target = t.cat([x_target, pred.max(2)[1]], 1).detach()\n",
    "    \n",
    "            # should you stop ?\n",
    "            count_eos += t.sum((pred.max(2)[1] == EOS_TOKEN).long()).data.cpu().numpy()[0]  # `3` is the EOS token\n",
    "            time += 1\n",
    "        return x_target\n",
    "        \n",
    "    \n",
    "    def translate_beam(self, x_source):\n",
    "        # INITIALIZE\n",
    "        self.eval()       \n",
    "\n",
    "        self.hidden_enc = self.init_hidden()\n",
    "        self.hidden_dec = self.init_hidden()\n",
    "        hidden = self.hidden_dec\n",
    "\n",
    "        count_eos = 0\n",
    "        time = 0        \n",
    "              \n",
    "        x_target = (SOS_TOKEN * t.ones(x_source.size(0), 1)).long()  # `2` is the SOS token (<s>)\n",
    "        #x_target = variable(x_target, to_float=False, cuda=self.cuda_flag)\n",
    "        \n",
    " \n",
    "        terminate_beam = False\n",
    "\n",
    "        # EMBEDDING\n",
    "        xx_source = self.reverse_source(x_source)\n",
    "        embedded_x_source = self.source_embeddings(xx_source)\n",
    "        if self.embed_dropout:\n",
    "            embedded_x_source = self.dropout_1s(embedded_x_source)\n",
    "\n",
    "        # ENCODING SOURCE SENTENCE INTO FIXED LENGTH VECTOR\n",
    "        _, self.hidden_enc = self.encoder_rnn(embedded_x_source, self.hidden_enc)\n",
    "        batch_size = x_source.size(0)\n",
    "        \n",
    "        #BEAM WILL BE MAINTAINED AS BATCH_SIZE * BEAM_SIZE\n",
    "        self.beam = np.array([x_target])\n",
    "        self.beam_scores = np.zeros((batch_size,1))\n",
    "       \n",
    "        while not terminate_beam and time < 20:\n",
    "            collective_children   = np.array([])\n",
    "            collective_scores     = np.array([])\n",
    "           \n",
    "            if len(self.beam) == 1:\n",
    "                reshaped_beam = self.beam\n",
    "            else:\n",
    "                reshaped_beam = self.beam.reshape((self.beam_size,batch_size,time+1))\n",
    "                reshaped_beam = t.from_numpy(reshaped_beam)\n",
    "\n",
    "            for it, elem in enumerate(reshaped_beam) :        \n",
    "                x_target = elem.view(self.batch_size,-1)\n",
    "                x_target = variable(x_target, to_float=False, cuda=self.cuda_flag).long()\n",
    "                embedded_x_target = self.target_embeddings(x_target)\n",
    "                embedded_x_target = self.append_hidden_to_target(embedded_x_target)\n",
    "                dec_out, hidden = self.decoder_rnn(embedded_x_target, hidden)\n",
    "                hidden = hidden[0].detach(), hidden[1].detach()\n",
    "                dec_out = dec_out[:, time:time + 1, :].detach()\n",
    "                dec_out = self.dropout_2(dec_out)\n",
    "                \n",
    "                # OUTPUT     \n",
    "                pred = self.hidden2out(dec_out).detach()\n",
    "                pred = self.lsm(pred).detach()\n",
    "\n",
    "                topk = t.topk(pred, self.beam_size,dim=2)\n",
    "                top_k_indices, top_k_scores = topk[1],topk[0]                    \n",
    "                top_k_indices = top_k_indices.view(self.beam_size,batch_size)\n",
    "                top_k_scores = top_k_scores.view(self.beam_size,batch_size)\n",
    "\n",
    "                for new_word_batch, new_score_batch in zip(top_k_indices, top_k_scores):                    \n",
    "                    new_word_batch, new_score_batch = new_word_batch.view(batch_size,1),new_score_batch.view(batch_size,1)\n",
    "                    new_child_batch = t.cat([x_target,new_word_batch],1).detach()                    \n",
    "                   \n",
    "                    batch_parent_score = self.beam_scores[:,it].reshape((self.batch_size,1))\n",
    "                    batch_acc_score =  batch_parent_score + new_score_batch.data.numpy()        \n",
    "                \n",
    "                    if len(collective_children) > 0:\n",
    "                        collective_children = np.hstack((collective_children, new_child_batch.data.numpy())) \n",
    "                        #Add the corresponding beam element's score with the new score and stack it.\n",
    "                        collective_scores   = np.hstack((collective_scores, batch_acc_score ))              \n",
    "                    else:\n",
    "                        collective_children, collective_scores = new_child_batch.data.numpy(),batch_acc_score               \n",
    "\n",
    "                     \n",
    "            #At the end of a for loop collective children, collective scores \n",
    "            #will look a numpy array of tensors.            \n",
    "            current_beam_length = 1 #Means only start elem is there.\n",
    "            if len(self.beam)!= 1:\n",
    "                current_beam_length = self.beam.shape[1]                \n",
    "                  \n",
    "            collective_children = collective_children.reshape((batch_size, current_beam_length*self.beam_size, \n",
    "                                                               int(collective_children.shape[1]/\n",
    "                                                                   current_beam_length/self.beam_size)\n",
    "                                                             ))\n",
    "            \n",
    "            if collective_children.shape[1] == self.beam_size:  #Happens the first time.\n",
    "                self.beam = collective_children  \n",
    "                self.beam_scores = collective_scores\n",
    "                \n",
    "            else:\n",
    "                self.beam = deepcopy(np.zeros((batch_size,self.beam_size,collective_children.shape[2])))\n",
    "                for i in range(batch_size):\n",
    "                    #Since argsort gives ascending order\n",
    "                    best_scores_indices = np.argsort(-1*collective_scores[i])[:self.beam_size]  \n",
    "                    for key,index in enumerate(best_scores_indices):\n",
    "                        self.beam[i][key][:] = collective_children[i][index]\n",
    "                        self.beam_scores[i][key] = collective_scores[i][index]\n",
    "            \n",
    "            terminate_beam = True\n",
    "            \n",
    "            for x in self.beam:\n",
    "                    for c in x:\n",
    "                        if EOS_TOKEN not in c:\n",
    "                            terminate_beam = False\n",
    "                            break\n",
    "                    if not terminate_beam:\n",
    "                        break   \n",
    "            #import pdb; pdb.set_trace()\n",
    "            assert(self.beam.shape == (batch_size,self.beam_size,time+2))\n",
    "\n",
    "            time += 1\n",
    "            print(time)\n",
    "        return self.beam\n",
    "\n",
    "    @staticmethod\n",
    "    def reverse_source(x):\n",
    "        \"\"\"\n",
    "        Reverse the source sentence x. Empirically it was observed to work better in terms of final valid PPL, and especially for long sentences\n",
    "        `x` is the integer-encoded sentence. It is a batch x sentence_length LongTensor\n",
    "        \"\"\"\n",
    "        # asssume that the batch_size is the first dim\n",
    "        return variable(t.cat([x.data[:, -1:]] + [x.data[:, -(k + 1):-k] for k in range(1, x.size(1))], 1), to_float=False)\n",
    "\n",
    "    def append_hidden_to_target(self, x):\n",
    "        \"\"\"Append self.hidden_enc to all timesteps of x\"\"\"\n",
    "        # self.hidden_enc[0] this is h. Size num_layers x batch x hdim\n",
    "        h = self.hidden_enc[0]\n",
    "        # h[-1:, :, :].permute(1,0,2) this is h for the last layer. Size batch x 1 x hdim\n",
    "        h_last = h[-1:, :, :].permute(1, 0, 2)\n",
    "        hidden = t.cat(x.size(1) * [h_last], 1)\n",
    "        return t.cat([x, hidden], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_source = Variable(t.ones((32,20))).long()\n",
    "params = {'source_vocab_size':10000,'target_vocab_size':10000,'embedding_dim':50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing LSTM\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTM (\n",
       "  (source_embeddings): Embedding(10000, 50)\n",
       "  (target_embeddings): Embedding(10000, 50)\n",
       "  (encoder_rnn): LSTM(50, 100, batch_first=True, dropout=0.5)\n",
       "  (decoder_rnn): LSTM(150, 100, batch_first=True, dropout=0.5)\n",
       "  (hidden2out): Linear (100 -> 10000)\n",
       "  (dropout_2): Dropout (p = 0.5)\n",
       "  (lsm): LogSoftmax ()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM(params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "final_beam = model.translate_beam(x_source)\n",
    "print(final_beam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
