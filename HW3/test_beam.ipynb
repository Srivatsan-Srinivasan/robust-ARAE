{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_TOKEN=2\n",
    "EOS_TOKEN=3\n",
    "class LSTM(t.nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of `Sequence to Sequence Learning with Neural Networks`\n",
    "    https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "\n",
    "    NOTE THAT ITS INPUT SHOULD HAVE THE BATCH SIZE FIRST !!!!!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, source_embeddings=None, target_embeddings=None):\n",
    "        super(LSTM, self).__init__()\n",
    "        print(\"Initializing LSTM\")\n",
    "        self.cuda_flag = params.get('cuda', CUDA_DEFAULT)\n",
    "        self.model_str = 'LSTM'\n",
    "        self.params = params\n",
    "\n",
    "        # Initialize hyperparams.\n",
    "        self.hidden_dim = params.get('hidden_dim', 100)\n",
    "        self.batch_size = params.get('batch_size', 32)\n",
    "        try:\n",
    "            # if you provide pre-trained embeddings for target/source, they should have the same embedding dim\n",
    "            self.source_vocab_size = params.get('source_vocab_size')\n",
    "            self.target_vocab_size = params.get('target_vocab_size')\n",
    "            assert source_embeddings.size(1) == target_embeddings.size(1)\n",
    "            self.embedding_dim = source_embeddings.size(1)\n",
    "        except:\n",
    "            # if you dont provide a pre-trained embedding, you have to provide these\n",
    "            self.source_vocab_size = params.get('source_vocab_size')\n",
    "            self.target_vocab_size = params.get('target_vocab_size')\n",
    "            self.embedding_dim = params.get('embedding_dim')\n",
    "            assert self.embedding_dim is not None and self.source_vocab_size is not None and self.target_vocab_size is not None\n",
    "        self.output_size = self.target_vocab_size\n",
    "        self.num_layers = params.get('num_layers', 1)\n",
    "        self.dropout = params.get('dropout', 0.5)\n",
    "        self.embed_dropout = params.get('embed_dropout')\n",
    "        self.train_embedding = params.get('train_embedding', False)\n",
    "\n",
    "        # Initialize embeddings. Static embeddings for now.\n",
    "        self.source_embeddings = t.nn.Embedding(self.source_vocab_size, self.embedding_dim)\n",
    "        self.target_embeddings = t.nn.Embedding(self.target_vocab_size, self.embedding_dim)\n",
    "        if source_embeddings is not None:\n",
    "            self.source_embeddings.weight = t.nn.Parameter(source_embeddings, requires_grad=self.train_embedding)\n",
    "        if target_embeddings is not None:\n",
    "            self.target_embeddings.weight = t.nn.Parameter(target_embeddings, requires_grad=self.train_embedding)\n",
    "\n",
    "        # Initialize network modules.\n",
    "        self.encoder_rnn = t.nn.LSTM(self.embedding_dim, self.hidden_dim, dropout=self.dropout, num_layers=self.num_layers, batch_first=True)\n",
    "        self.decoder_rnn = t.nn.LSTM(self.embedding_dim + self.hidden_dim, self.hidden_dim, dropout=self.dropout, num_layers=self.num_layers, batch_first=True)\n",
    "        self.hidden2out = t.nn.Linear(self.hidden_dim, self.output_size)\n",
    "        self.hidden_enc = self.init_hidden()\n",
    "        self.hidden_dec = self.init_hidden()\n",
    "        if self.embed_dropout:\n",
    "            self.dropout_1s = t.nn.Dropout(self.dropout)\n",
    "            self.dropout_1t = t.nn.Dropout(self.dropout)\n",
    "        self.dropout_2 = t.nn.Dropout(self.dropout)\n",
    "        \n",
    "        # Beam Search related.\n",
    "        self.beam = np.array([])   \n",
    "        self.beam_size = params.get('beam_size',3)\n",
    "                \n",
    "    def init_hidden(self, batch_size=None):\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim). The helper function\n",
    "        # will return torch variable.\n",
    "        bs = self.batch_size if batch_size is None else batch_size\n",
    "        return tuple((\n",
    "            variable(np.zeros((self.num_layers, bs, self.hidden_dim)), cuda=self.cuda_flag),\n",
    "            variable(np.zeros((self.num_layers, bs, self.hidden_dim)), cuda=self.cuda_flag)\n",
    "        ))\n",
    "\n",
    "    def forward(self, x_source, x_target):\n",
    "        \"\"\"\n",
    "        :param x_source: the source sentence\n",
    "        :param x_target: the target (translated) sentence\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # EMBEDDING\n",
    "        xx_source = self.reverse_source(x_source)\n",
    "        embedded_x_source = self.source_embeddings(xx_source)\n",
    "        embedded_x_target = self.source_embeddings(x_target[:, :-1])\n",
    "        if self.embed_dropout:\n",
    "            embedded_x_source = self.dropout_1s(embedded_x_source)\n",
    "            embedded_x_target = self.dropout_1t(embedded_x_target)\n",
    "\n",
    "        # ENCODING SOURCE SENTENCE INTO FIXED LENGTH VECTOR\n",
    "        _, self.hidden_enc = self.encoder_rnn(embedded_x_source, self.hidden_enc)\n",
    "\n",
    "        # DECODING\n",
    "        embedded_x_target = self.append_hidden_to_target(embedded_x_target)\n",
    "        rnn_out, self.hidden_dec = self.decoder_rnn(embedded_x_target, self.hidden_dec)\n",
    "        rnn_out = self.dropout_2(rnn_out)\n",
    "\n",
    "        # OUTPUT\n",
    "        out_linear = self.hidden2out(rnn_out)\n",
    "        return out_linear\n",
    "    \n",
    "    def translate(self, x_source):\n",
    "        # INITIALIZE\n",
    "        self.eval()\n",
    "    \n",
    "        self.hidden_enc = self.init_hidden()\n",
    "        self.hidden_dec = self.init_hidden()\n",
    "        hidden = self.hidden_dec\n",
    "    \n",
    "        count_eos = 0\n",
    "        time = 0\n",
    "    \n",
    "        x_target = (SOS_TOKEN * t.ones(x_source.size(0), 1)).long()  # `2` is the SOS token (<s>)\n",
    "        x_target = variable(x_target, to_float=False, cuda=self.cuda_flag)\n",
    "    \n",
    "        # EMBEDDING\n",
    "        xx_source = self.reverse_source(x_source)\n",
    "        embedded_x_source = self.source_embeddings(xx_source)\n",
    "        if self.embed_dropout:\n",
    "            embedded_x_source = self.dropout_1s(embedded_x_source)\n",
    "    \n",
    "        # ENCODING SOURCE SENTENCE INTO FIXED LENGTH VECTOR\n",
    "        _, self.hidden_enc = self.encoder_rnn(embedded_x_source, self.hidden_enc)\n",
    "    \n",
    "        while count_eos < x_source.size(0):\n",
    "            embedded_x_target = self.target_embeddings(x_target)\n",
    "            embedded_x_target = self.append_hidden_to_target(embedded_x_target)\n",
    "            dec_out, hidden = self.decoder_rnn(embedded_x_target, hidden)\n",
    "            hidden = hidden[0].detach(), hidden[1].detach()\n",
    "            dec_out = dec_out[:, time:time + 1, :].detach()\n",
    "            dec_out = self.dropout_2(dec_out)\n",
    "    \n",
    "            # OUTPUT\n",
    "            pred = self.hidden2out(dec_out).detach()\n",
    "            # concatenate the output of the decoder and the context and apply nonlinearity\n",
    "            x_target = t.cat([x_target, pred.max(2)[1]], 1).detach()\n",
    "    \n",
    "            # should you stop ?\n",
    "            count_eos += t.sum((pred.max(2)[1] == EOS_TOKEN).long()).data.cpu().numpy()[0]  # `3` is the EOS token\n",
    "            time += 1\n",
    "        return x_target\n",
    "        \n",
    "    \n",
    "    def translate_beam(self, x_source):\n",
    "        # INITIALIZE\n",
    "        self.eval()       \n",
    "\n",
    "        self.hidden_enc = self.init_hidden()\n",
    "        self.hidden_dec = self.init_hidden()\n",
    "        hidden = self.hidden_dec\n",
    "\n",
    "        count_eos = 0\n",
    "        time = 0        \n",
    "              \n",
    "        x_target = (SOS_TOKEN * t.ones(x_source.size(0), 1)).long()  # `2` is the SOS token (<s>)\n",
    "        #x_target = variable(x_target, to_float=False, cuda=self.cuda_flag)\n",
    "        \n",
    "        #BEAM WILL BE MAINTAINED AS BATCH_SIZE * BEAM_SIZE\n",
    "        self.beam = np.array([x_target])\n",
    "        terminate_beam = False\n",
    "\n",
    "        # EMBEDDING\n",
    "        xx_source = self.reverse_source(x_source)\n",
    "        embedded_x_source = self.source_embeddings(xx_source)\n",
    "        if self.embed_dropout:\n",
    "            embedded_x_source = self.dropout_1s(embedded_x_source)\n",
    "\n",
    "        # ENCODING SOURCE SENTENCE INTO FIXED LENGTH VECTOR\n",
    "        _, self.hidden_enc = self.encoder_rnn(embedded_x_source, self.hidden_enc)\n",
    "        batch_size = x_source.size(0)\n",
    "       \n",
    "        while not terminate_beam and time < 50:\n",
    "            collective_children   = np.array([])\n",
    "            collective_scores     = np.array([])\n",
    "           \n",
    "            if len(self.beam) == 1:\n",
    "                reshaped_beam = self.beam\n",
    "            else:\n",
    "                reshaped_beam = self.beam.reshape((self.beam_size,batch_size,time+1))\n",
    "                reshaped_beam = t.from_numpy(reshaped_beam)\n",
    "\n",
    "            for elem in reshaped_beam :        \n",
    "                x_target = elem.view(self.batch_size,-1)\n",
    "                x_target = variable(x_target, to_float=False, cuda=self.cuda_flag).long()\n",
    "                embedded_x_target = self.target_embeddings(x_target)\n",
    "                embedded_x_target = self.append_hidden_to_target(embedded_x_target)\n",
    "                dec_out, hidden = self.decoder_rnn(embedded_x_target, hidden)\n",
    "                hidden = hidden[0].detach(), hidden[1].detach()\n",
    "                dec_out = dec_out[:, time:time + 1, :].detach()\n",
    "                dec_out = self.dropout_2(dec_out)\n",
    "                \n",
    "                # OUTPUT        \n",
    "\n",
    "\n",
    "                pred = self.hidden2out(dec_out).detach()\n",
    "\n",
    "                topk = t.topk(pred, self.beam_size,dim=2)\n",
    "                top_k_indices, top_k_scores = topk[1],topk[0]                    \n",
    "                top_k_indices = top_k_indices.view(self.beam_size,batch_size)\n",
    "                top_k_scores = top_k_scores.view(self.beam_size,batch_size)\n",
    "\n",
    "                for new_word_batch, new_score_batch in zip(top_k_indices, top_k_scores):                    \n",
    "                    new_word_batch, new_score_batch = new_word_batch.view(batch_size,1),new_score_batch.view(batch_size,1)\n",
    "                    new_child_batch = t.cat([x_target,new_word_batch],1).detach()\n",
    "                    if len(collective_children) > 0:\n",
    "                        collective_children = np.hstack((collective_children, new_child_batch.data.numpy())) \n",
    "                        collective_scores = np.hstack((collective_scores, new_score_batch.data.numpy()))              \n",
    "                    else:\n",
    "                        collective_children, collective_scores = new_child_batch.data.numpy(),new_score_batch.data.numpy()                \n",
    "\n",
    "                     \n",
    "            #At the end of a for loop collective children, collective scores \n",
    "            #will look a numpy array of tensors.            \n",
    "            current_beam_length = 1 #Means only start elem is there.\n",
    "            if len(self.beam)!= 1:\n",
    "                current_beam_length = self.beam.shape[1]\n",
    "                \n",
    "                  \n",
    "            collective_children = collective_children.reshape((batch_size, current_beam_length*self.beam_size, \n",
    "                                                               int(collective_children.shape[1]/\n",
    "                                                                   current_beam_length/self.beam_size)\n",
    "                                                             ))\n",
    "            \n",
    "            if collective_children.shape[1] == self.beam_size:  #Happens the first time.\n",
    "                self.beam = collective_children                                \n",
    "            else:\n",
    "                self.beam = deepcopy(np.zeros((batch_size,self.beam_size,collective_children.shape[2])))\n",
    "                for i in range(batch_size):\n",
    "                    #Since argsort gives ascending order\n",
    "                    best_scores_indices = np.argsort(-1*collective_scores[i])[:self.beam_size]                    \n",
    "                    for key,index in enumerate(best_scores_indices):\n",
    "                        self.beam[i][key][:] = collective_children[i][index]\n",
    "            \n",
    "            terminate_beam = True\n",
    "            #Check if every beam has EOS token and it has happened for all elements in the batch.\n",
    "            for x in self.beam:\n",
    "                    for c in x:\n",
    "                        if EOS_TOKEN not in c:\n",
    "                            terminate_beam = False\n",
    "                            break\n",
    "                    if not terminate_beam:\n",
    "                        break   \n",
    "            \n",
    "            assert(self.beam.shape == (batch_size,self.beam_size,time+2))\n",
    "\n",
    "            time += 1\n",
    "        return self.beam\n",
    "\n",
    "    @staticmethod\n",
    "    def reverse_source(x):\n",
    "        \"\"\"\n",
    "        Reverse the source sentence x. Empirically it was observed to work better in terms of final valid PPL, and especially for long sentences\n",
    "        `x` is the integer-encoded sentence. It is a batch x sentence_length LongTensor\n",
    "        \"\"\"\n",
    "        # asssume that the batch_size is the first dim\n",
    "        return variable(t.cat([x.data[:, -1:]] + [x.data[:, -(k + 1):-k] for k in range(1, x.size(1))], 1), to_float=False)\n",
    "\n",
    "    def append_hidden_to_target(self, x):\n",
    "        \"\"\"Append self.hidden_enc to all timesteps of x\"\"\"\n",
    "        # self.hidden_enc[0] this is h. Size num_layers x batch x hdim\n",
    "        h = self.hidden_enc[0]\n",
    "        # h[-1:, :, :].permute(1,0,2) this is h for the last layer. Size batch x 1 x hdim\n",
    "        h_last = h[-1:, :, :].permute(1, 0, 2)\n",
    "        hidden = t.cat(x.size(1) * [h_last], 1)\n",
    "        return t.cat([x, hidden], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "os.chdir('../HW3')  # so that there is not any import bug in case HW2 is not already the working directory\n",
    "from utils import *\n",
    "from const import *\n",
    "import argparse\n",
    "import torch as t\n",
    "from process_params import check_args, get_params\n",
    "from const import *\n",
    "from train_models import train, validate\n",
    "from data_process import generate_iterators, generate_text\n",
    "from utils import *\n",
    "t.manual_seed(1)\n",
    "\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "from utils import variable\n",
    "from const import *\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import spacy\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import pickle\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_iterators(BATCH_SIZE=32, MAX_LEN=20, load_data=False):\n",
    "    if not load_data:\n",
    "        spacy_de = spacy.load('de')\n",
    "        spacy_en = spacy.load('en')\n",
    "\n",
    "        def tokenize_de(text):\n",
    "            return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "        def tokenize_en(text):\n",
    "            return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "        BOS_WORD = '<s>'\n",
    "        EOS_WORD = '</s>'\n",
    "        DE = data.Field(tokenize=tokenize_de)\n",
    "        EN = data.Field(tokenize=tokenize_en, init_token=BOS_WORD, eos_token=EOS_WORD)  # only target needs BOS/EOS\n",
    "\n",
    "        train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(DE, EN),\n",
    "                                                 filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and\n",
    "                                                                       len(vars(x)['trg']) <= MAX_LEN)\n",
    "        MIN_FREQ = 5\n",
    "        DE.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "        EN.build_vocab(train.trg, min_freq=MIN_FREQ)\n",
    "        train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=BATCH_SIZE, device=-1,\n",
    "                                                          repeat=False, sort_key=lambda x: len(x.src))\n",
    "\n",
    "        return train_iter, val_iter, EN, DE\n",
    "    else:  # does not work...\n",
    "        with open('train.pkl', 'rb') as f:\n",
    "            train = pickle.load(f)\n",
    "        with open('val.pkl', 'rb') as f:\n",
    "            val = pickle.load(f)\n",
    "        with open('DE.torchtext.Field.pkl', 'rb') as f:\n",
    "            DE = pickle.load(f)\n",
    "        with open('EN.torchtext.Field.pkl', 'rb') as f:\n",
    "            EN = pickle.load(f)\n",
    "        BATCH_SIZE = 32\n",
    "        train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=BATCH_SIZE, device=-1,\n",
    "                                                          repeat=False, sort_key=lambda x: len(x.src))\n",
    "        return train_iter, val_iter, EN, DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading de-en.tgz\n",
      ".data\\iwslt\\de-en\\IWSLT16.TED.dev2010.de-en.de.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TED.dev2010.de-en.en.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TED.tst2010.de-en.de.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TED.tst2010.de-en.en.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TED.tst2011.de-en.de.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TED.tst2011.de-en.en.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TED.tst2012.de-en.de.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TED.tst2012.de-en.en.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TED.tst2013.de-en.de.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TED.tst2013.de-en.en.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TED.tst2014.de-en.de.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TED.tst2014.de-en.en.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TEDX.dev2012.de-en.de.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TEDX.dev2012.de-en.en.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TEDX.tst2013.de-en.de.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TEDX.tst2013.de-en.en.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TEDX.tst2014.de-en.de.xml\n",
      ".data\\iwslt\\de-en\\IWSLT16.TEDX.tst2014.de-en.en.xml\n",
      ".data\\iwslt\\de-en\\train.tags.de-en.de\n",
      ".data\\iwslt\\de-en\\train.tags.de-en.en\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 2213: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-789147f48958>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load data code should be here. Vocab size function of text.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_iterators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAX_LEN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'source_vocab_size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target_vocab_size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-4ac70bfe354b>\u001b[0m in \u001b[0;36mgenerate_iterators\u001b[1;34m(BATCH_SIZE, MAX_LEN, load_data)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(DE, EN),\n\u001b[1;32m---> 18\u001b[1;33m                                                  \u001b[0mfilter_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'src'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mMAX_LEN\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m                                                                        len(vars(x)['trg']) <= MAX_LEN)\n\u001b[0;32m     20\u001b[0m         \u001b[0mMIN_FREQ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SrivatsanPC\\Anaconda3\\lib\\site-packages\\torchtext\\datasets\\translation.py\u001b[0m in \u001b[0;36msplits\u001b[1;34m(cls, exts, fields, root, train, validation, test, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         train_data = None if train is None else cls(\n\u001b[1;32m--> 141\u001b[1;33m             os.path.join(path, train), exts, fields, **kwargs)\n\u001b[0m\u001b[0;32m    142\u001b[0m         val_data = None if validation is None else cls(\n\u001b[0;32m    143\u001b[0m             os.path.join(path, validation), exts, fields, **kwargs)\n",
      "\u001b[1;32mC:\\Users\\SrivatsanPC\\Anaconda3\\lib\\site-packages\\torchtext\\datasets\\translation.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, exts, fields, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mexamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msrc_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrg_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrg_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msrc_line\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m                 \u001b[0msrc_line\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc_line\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg_line\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msrc_line\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m''\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtrg_line\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SrivatsanPC\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 2213: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "# Load data code should be here. Vocab size function of text.\n",
    "train_iter, val_iter, EN, DE = generate_iterators(MAX_LEN=20, load_data=False, BATCH_SIZE=32)\n",
    "model_params['source_vocab_size'] = len(DE.vocab.itos)\n",
    "model_params['target_vocab_size'] = len(EN.vocab.itos)\n",
    "args = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-b0487e9b86ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx_source\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'source_vocab_size'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'target_vocab_size'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'embedding_dim'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'DE' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 2213: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-98338e2fe7bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mEN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenize_en\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_token\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBOS_WORD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meos_token\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEOS_WORD\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# only target needs BOS/EOS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(DE, EN),\n\u001b[1;32m---> 15\u001b[1;33m                                          \u001b[0mfilter_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'src'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mMAX_LEN\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                                                                len(vars(x)['trg']) <= MAX_LEN)\n\u001b[0;32m     17\u001b[0m \u001b[0mMIN_FREQ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SrivatsanPC\\Anaconda3\\lib\\site-packages\\torchtext\\datasets\\translation.py\u001b[0m in \u001b[0;36msplits\u001b[1;34m(cls, exts, fields, root, train, validation, test, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         train_data = None if train is None else cls(\n\u001b[1;32m--> 141\u001b[1;33m             os.path.join(path, train), exts, fields, **kwargs)\n\u001b[0m\u001b[0;32m    142\u001b[0m         val_data = None if validation is None else cls(\n\u001b[0;32m    143\u001b[0m             os.path.join(path, validation), exts, fields, **kwargs)\n",
      "\u001b[1;32mC:\\Users\\SrivatsanPC\\Anaconda3\\lib\\site-packages\\torchtext\\datasets\\translation.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, exts, fields, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mexamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msrc_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrg_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtrg_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msrc_line\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg_line\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m                 \u001b[0msrc_line\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc_line\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg_line\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msrc_line\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m''\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtrg_line\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\SrivatsanPC\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 2213: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "DE = data.Field(tokenize=tokenize_de)\n",
    "EN = data.Field(tokenize=tokenize_en, init_token=BOS_WORD, eos_token=EOS_WORD)  # only target needs BOS/EOS\n",
    "train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(DE, EN),\n",
    "                                         filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and\n",
    "                                                               len(vars(x)['trg']) <= MAX_LEN)\n",
    "MIN_FREQ = 5\n",
    "DE.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "EN.build_vocab(train.trg, min_freq=MIN_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_source = Variable(t.ones((32,20))).long()\n",
    "params = {'source_vocab_size':10000,'target_vocab_size':10000,'embedding_dim':50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing LSTM\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTM (\n",
       "  (source_embeddings): Embedding(10000, 50)\n",
       "  (target_embeddings): Embedding(10000, 50)\n",
       "  (encoder_rnn): LSTM(50, 100, batch_first=True, dropout=0.5)\n",
       "  (decoder_rnn): LSTM(150, 100, batch_first=True, dropout=0.5)\n",
       "  (hidden2out): Linear (100 -> 10000)\n",
       "  (dropout_2): Dropout (p = 0.5)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM(params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3, 51)\n"
     ]
    }
   ],
   "source": [
    "final_beam = model.translate_beam(x_source)\n",
    "print(final_beam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred.max(2)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
