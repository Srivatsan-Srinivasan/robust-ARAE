{'tensorboard_freq': 2000, 'min_epochs': 3, 'noise_anneal': 0.995, 'tie_weights': False, 'log_interval': 200, 'dropout_penalty': None, 'POS_vocab': True, 'noise_radius': 0.2, 'lambda_GP': 10.0, 'batch_size': 64, 'temp': 1, 'tensorboard_logdir': 'exp24', 'data_path': 'snli_lm', 'ntokens': 11011, 'polar': False, 'hidden_init': False, 'gan_activation': 'lrelu', 'seed': 45, 'emsize': 300, 'epochs': 15, 'enc_grad_norm': True, 'z_size': 100, 'gradient_penalty': True, 'std_minibatch': False, 'patience': 5, 'lr_gan_g': 5e-05, 'bidirectionnal': True, 'gan_weight_init': 'default', 'nhidden_dec': 500, 'sample': False, 'tensorboard': True, 'maxlen': 30, 'progressive_vocab': True, 'gpu_id': None, 'lr_gan_d': 1e-05, 'norm_penalty': None, 'vocabulary_switch_cutoff': 0.75, 'lr_ae': 1, 'cuda': True, 'timeit': 50000, 'N': 5, 'niters_gan_schedule': '2-4-6', 'niters_gan_g': 1, 'arch_d': '300-300', 'l2_reg_disc': None, 'clip': 1, 'outf': 'exp24', 'gan_toenc': -0.01, 'kenlm_path': '../Data/kenlm', 'n_gpus': 1, 'bn_disc': True, 'lowercase': False, 'niters_ae': 1, 'lambda_dropout': None, 'dropout': 0.5, 'gan_clamp': 0.01, 'bn_gen': True, 'eps_drift': 0.001, 'nlayers': 1, 'no_earlystopping': False, 'spectralnorm': False, 'nhidden_enc': 300, 'ae_lr_scheduler': False, 'vocab_size': 11000, 'beta1': 0.9, 'optim_gan': 'adam', 'niters_gan_d': 5, 'arch_g': '500-500'}

Training...
[1/15][99/11134] Loss_D: 0.30305517 (Loss_D_real: 0.00171084 Loss_D_fake: 0.30476600) Loss_G: 0.30766138
[1/15][199/11134] Loss_D: 0.46632338 (Loss_D_real: -0.01003134 Loss_D_fake: 0.45629203) Loss_G: 0.44714585
[1/15][299/11134] Loss_D: 0.73105687 (Loss_D_real: -0.11207198 Loss_D_fake: 0.61898488) Loss_G: 0.61564046
[1/15][399/11134] Loss_D: 0.98076105 (Loss_D_real: -0.18979260 Loss_D_fake: 0.79096848) Loss_G: 0.80052209
[1/15][499/11134] Loss_D: 1.10936844 (Loss_D_real: -0.18026961 Loss_D_fake: 0.92909878) Loss_G: 0.95003629
[1/15][599/11134] Loss_D: 0.98030412 (Loss_D_real: 0.10245621 Loss_D_fake: 1.08276033) Loss_G: 1.08095312
[1/15][699/11134] Loss_D: 1.22690988 (Loss_D_real: -0.02917564 Loss_D_fake: 1.19773424) Loss_G: 1.26729417
[1/15][799/11134] Loss_D: 1.37985349 (Loss_D_real: -0.00143408 Loss_D_fake: 1.37841940) Loss_G: 1.35161185
[1/15][899/11134] Loss_D: 1.87588751 (Loss_D_real: -0.41117701 Loss_D_fake: 1.46471047) Loss_G: 1.48768783
[1/15][999/11134] Loss_D: 1.49362028 (Loss_D_real: 0.04869407 Loss_D_fake: 1.54231429) Loss_G: 1.57788157
[1/15][99/11134] Loss_D: 1.21734309 (Loss_D_real: 0.41079921 Loss_D_fake: 1.62814224) Loss_G: 1.61441612
[1/15][199/11134] Loss_D: 1.77886832 (Loss_D_real: -0.00018683 Loss_D_fake: 1.77868152) Loss_G: 1.76105869
[1/15][299/11134] Loss_D: 1.48810685 (Loss_D_real: 0.53825462 Loss_D_fake: 2.02636147) Loss_G: 2.05716872
[1/15][399/11134] Loss_D: 2.64546824 (Loss_D_real: -0.37055218 Loss_D_fake: 2.27491617) Loss_G: 2.28143263
[1/15][499/11134] Loss_D: 1.27714479 (Loss_D_real: 1.26181328 Loss_D_fake: 2.53895807) Loss_G: 2.53876257
[1/15][599/11134] Loss_D: 3.38651037 (Loss_D_real: -0.75450456 Loss_D_fake: 2.63200593) Loss_G: 2.58741832
[1/15][699/11134] Loss_D: 2.14153767 (Loss_D_real: 0.28796184 Loss_D_fake: 2.42949963) Loss_G: 2.47183800
[1/15][799/11134] Loss_D: 1.76196837 (Loss_D_real: 0.81549144 Loss_D_fake: 2.57745981) Loss_G: 2.65341902
[1/15][899/11134] Loss_D: 3.61617923 (Loss_D_real: -1.20803666 Loss_D_fake: 2.40814257) Loss_G: 2.36843944
[1/15][999/11134] Loss_D: 2.98183584 (Loss_D_real: -0.79818213 Loss_D_fake: 2.18365359) Loss_G: 2.20576215
[1/15][99/11134] Loss_D: 1.07284403 (Loss_D_real: 1.00669003 Loss_D_fake: 2.07953405) Loss_G: 2.08973289
[1/15][199/11134] Loss_D: 1.81612098 (Loss_D_real: 0.34291661 Loss_D_fake: 2.15903759) Loss_G: 2.13818216
[1/15][299/11134] Loss_D: 1.56499195 (Loss_D_real: 0.71524185 Loss_D_fake: 2.28023386) Loss_G: 2.23904085
[1/15][399/11134] Loss_D: 3.62321615 (Loss_D_real: -1.29676354 Loss_D_fake: 2.32645273) Loss_G: 2.17318082
[1/15][499/11134] Loss_D: 2.07564402 (Loss_D_real: 0.11793183 Loss_D_fake: 2.19357586) Loss_G: 2.18491101
[1/15][599/11134] Loss_D: 2.98700428 (Loss_D_real: -0.69299638 Loss_D_fake: 2.29400802) Loss_G: 2.37618423
[1/15][699/11134] Loss_D: 4.35166836 (Loss_D_real: -2.01580358 Loss_D_fake: 2.33586502) Loss_G: 2.31583023
[1/15][799/11134] Loss_D: -0.43918037 (Loss_D_real: 2.51498556 Loss_D_fake: 2.07580519) Loss_G: 2.13190389
[1/15][899/11134] Loss_D: 1.67755949 (Loss_D_real: 0.21381746 Loss_D_fake: 1.89137697) Loss_G: 2.10662103
[1/15][999/11134] Loss_D: 3.56263638 (Loss_D_real: -0.79841363 Loss_D_fake: 2.76422286) Loss_G: 2.57140541
[1/15][99/11134] Loss_D: 0.31429172 (Loss_D_real: 2.01147962 Loss_D_fake: 2.32577133) Loss_G: 2.35690665
[1/15][199/11134] Loss_D: 0.81462705 (Loss_D_real: 1.46169150 Loss_D_fake: 2.27631855) Loss_G: 2.14308214
[1/15][299/11134] Loss_D: -5.08706760 (Loss_D_real: 6.62806463 Loss_D_fake: 1.54099679) Loss_G: 1.66599476
[1/15][399/11134] Loss_D: 1.69586682 (Loss_D_real: -0.20542818 Loss_D_fake: 1.49043858) Loss_G: 1.42816472
[1/15][499/11134] Loss_D: 1.64558816 (Loss_D_real: 0.06820318 Loss_D_fake: 1.71379137) Loss_G: 1.68839443
[1/15][599/11134] Loss_D: -1.11183453 (Loss_D_real: 2.35751390 Loss_D_fake: 1.24567938) Loss_G: 1.33708417
[1/15][699/11134] Loss_D: -0.51919907 (Loss_D_real: 1.51225579 Loss_D_fake: 0.99305671) Loss_G: 1.05024445
[1/15][799/11134] Loss_D: -1.66091144 (Loss_D_real: 3.10424256 Loss_D_fake: 1.44333112) Loss_G: 1.49468803
[1/15][899/11134] Loss_D: -2.16377449 (Loss_D_real: 3.40357924 Loss_D_fake: 1.23980486) Loss_G: 1.32738459
[1/15][999/11134] Loss_D: 0.55167109 (Loss_D_real: 0.61857122 Loss_D_fake: 1.17024231) Loss_G: 1.22789764
[1/15][1099/11134] Loss_D: -0.75536025 (Loss_D_real: 2.19639087 Loss_D_fake: 1.44103062) Loss_G: 1.54919124
[1/15][1199/11134] Loss_D: -0.58612800 (Loss_D_real: 2.15086150 Loss_D_fake: 1.56473351) Loss_G: 1.48881757
[1/15][1299/11134] Loss_D: 1.36672735 (Loss_D_real: 0.89032918 Loss_D_fake: 2.25705647) Loss_G: 2.15635300
[1/15][1399/11134] Loss_D: -0.56328964 (Loss_D_real: 2.57338595 Loss_D_fake: 2.01009631) Loss_G: 1.94537663
[1/15][1499/11134] Loss_D: -0.42163444 (Loss_D_real: 2.10960555 Loss_D_fake: 1.68797112) Loss_G: 1.79066122
[1/15][1599/11134] Loss_D: 0.91412640 (Loss_D_real: 1.41303110 Loss_D_fake: 2.32715750) Loss_G: 2.33019781
[1/15][1699/11134] Loss_D: -1.09617746 (Loss_D_real: 3.05633354 Loss_D_fake: 1.96015608) Loss_G: 1.96068943
[1/15][1799/11134] Loss_D: 0.46560198 (Loss_D_real: 0.97633535 Loss_D_fake: 1.44193733) Loss_G: 1.44989204
[1/15][1899/11134] Loss_D: 0.64548159 (Loss_D_real: 1.26248312 Loss_D_fake: 1.90796471) Loss_G: 1.84138083
[1/15][1999/11134] Loss_D: -1.59664881 (Loss_D_real: 3.36447406 Loss_D_fake: 1.76782525) Loss_G: 1.68522882
[1/15][2099/11134] Loss_D: 0.34561133 (Loss_D_real: 1.22824490 Loss_D_fake: 1.57385623) Loss_G: 1.67871475
[1/15][2199/11134] Loss_D: 0.21153057 (Loss_D_real: 1.70442212 Loss_D_fake: 1.91595268) Loss_G: 1.85742545
[1/15][2299/11134] Loss_D: 0.11722004 (Loss_D_real: 1.84521663 Loss_D_fake: 1.96243668) Loss_G: 1.93022907
[1/15][2399/11134] Loss_D: -0.03656268 (Loss_D_real: 1.21454334 Loss_D_fake: 1.17798066) Loss_G: 1.14934826
[1/15][2499/11134] Loss_D: -2.15494061 (Loss_D_real: 3.27898908 Loss_D_fake: 1.12404835) Loss_G: 1.09281993
[1/15][2599/11134] Loss_D: 2.25536013 (Loss_D_real: -0.85476714 Loss_D_fake: 1.40059292) Loss_G: 1.55750942
[1/15][2699/11134] Loss_D: 3.71163940 (Loss_D_real: -2.10363078 Loss_D_fake: 1.60800850) Loss_G: 1.54528809
[1/15][2799/11134] Loss_D: 2.23829341 (Loss_D_real: -0.36137417 Loss_D_fake: 1.87691927) Loss_G: 1.68796194
[1/15][2899/11134] Loss_D: 2.21463990 (Loss_D_real: -1.10807693 Loss_D_fake: 1.10656297) Loss_G: 1.16005075
[1/15][2999/11134] Loss_D: 0.44145977 (Loss_D_real: 0.65204906 Loss_D_fake: 1.09350884) Loss_G: 1.14292777
[1/15][3099/11134] Loss_D: 0.86000985 (Loss_D_real: 0.43189579 Loss_D_fake: 1.29190564) Loss_G: 1.55592120
[1/15][3199/11134] Loss_D: 0.54499149 (Loss_D_real: -0.05476534 Loss_D_fake: 0.49022615) Loss_G: 0.45177007
[1/15][3299/11134] Loss_D: 1.31080914 (Loss_D_real: 0.68718648 Loss_D_fake: 1.99799562) Loss_G: 1.87508309
[1/15][3399/11134] Loss_D: 0.29114878 (Loss_D_real: 0.87420845 Loss_D_fake: 1.16535723) Loss_G: 1.20845819
